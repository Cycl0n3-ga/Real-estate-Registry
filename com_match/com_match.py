#!/usr/bin/env python3
"""
com_match.py â€” å»ºæ¡ˆåç¨±æ¨¡ç³Šæœå°‹å¼•æ“

åŠŸèƒ½ï¼š
  - è¼¸å…¥å»ºæ¡ˆé—œéµå­—ï¼ˆéƒ¨åˆ†åç¨±ã€æ‹¼å­—éŒ¯èª¤ç­‰ï¼‰ï¼Œå›å‚³æ‰€æœ‰å¯èƒ½åŒ¹é…çš„å»ºæ¡ˆ
  - ä½¿ç”¨ SQLite LIKE + å­åºåˆ—åŒ¹é… + ç·¨è¼¯è·é›¢ï¼Œå¤šå±¤æœå°‹
  - å›å‚³çµæœåŒ…å«äº¤æ˜“ç­†æ•¸ã€å‡åƒ¹ç­‰æ‘˜è¦

ä½¿ç”¨æ–¹å¼ï¼š
  from com_match import CommunityMatcher, fuzzy_search
  matcher = CommunityMatcher(db_path)
  results = matcher.search("é é›„å¹¸ç¦")
  # æˆ–å¿«é€Ÿå‘¼å«
  results = fuzzy_search("é é›„", db_path)
"""

import re
import sqlite3
import time
from pathlib import Path
from typing import List, Dict, Optional
from collections import defaultdict

# â”€â”€ è·¯å¾‘è¨­å®š â”€â”€
SCRIPT_DIR = Path(__file__).parent
LAND_DIR = SCRIPT_DIR.parent
DEFAULT_DB_PATH = str(LAND_DIR / "db" / "land_data.db")

# â”€â”€ å…¨å½¢åŠå½¢è½‰æ› â”€â”€
_FW_DIGITS = "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™"
_HW_DIGITS = "0123456789"
_FW_UPPER = "ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼º"
_HW_UPPER = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
_FW_LOWER = "ï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½š"
_HW_LOWER = "abcdefghijklmnopqrstuvwxyz"
_FW_TO_HW = str.maketrans(
    _FW_DIGITS + _FW_UPPER + _FW_LOWER,
    _HW_DIGITS + _HW_UPPER + _HW_LOWER,
)


def _normalize(name: str) -> str:
    """æ­£è¦åŒ–å»ºæ¡ˆåç¨±ï¼šå…¨å½¢â†’åŠå½¢ã€å¤§å¯«ã€å»ç©ºç™½"""
    if not name:
        return ""
    s = name.strip().translate(_FW_TO_HW).upper()
    s = re.sub(r'\s+', '', s)
    return s


def _edit_distance(a: str, b: str, max_dist: int = 5) -> int:
    """è¨ˆç®—ç·¨è¼¯è·é›¢ï¼ˆLevenshteinï¼‰ï¼Œè¶…é max_dist æå‰ä¸­æ­¢"""
    la, lb = len(a), len(b)
    if abs(la - lb) > max_dist:
        return max_dist + 1
    if la == 0:
        return lb
    if lb == 0:
        return la

    prev = list(range(lb + 1))
    for i in range(1, la + 1):
        curr = [i] + [0] * lb
        min_val = i
        for j in range(1, lb + 1):
            cost = 0 if a[i - 1] == b[j - 1] else 1
            curr[j] = min(curr[j - 1] + 1, prev[j] + 1, prev[j - 1] + cost)
            if curr[j] < min_val:
                min_val = curr[j]
        if min_val > max_dist:
            return max_dist + 1
        prev = curr
    return prev[lb]


def _is_subsequence(query: str, target: str) -> bool:
    """æª¢æŸ¥ query æ˜¯å¦ç‚º target çš„å­åºåˆ—"""
    qi = 0
    for ch in target:
        if qi < len(query) and ch == query[qi]:
            qi += 1
    return qi == len(query)


def _common_chars_ratio(a: str, b: str) -> float:
    """è¨ˆç®—å…±åŒå­—å…ƒæ¯”ç‡ï¼ˆç›¸å°æ–¼è¼ƒçŸ­å­—ä¸²ï¼‰"""
    if not a or not b:
        return 0.0
    sa = set(a)
    sb = set(b)
    common = len(sa & sb)
    return common / max(len(sa), len(sb))


class CommunityMatcher:
    """å»ºæ¡ˆåç¨±æ¨¡ç³Šæœå°‹å¼•æ“"""

    def __init__(self, db_path: str = None):
        self.db_path = db_path or DEFAULT_DB_PATH
        self._cache = None  # {normalized_name: (original_name, tx_count, avg_price, avg_unit_price, district)}
        self._load_cache()

    def _load_cache(self):
        """è¼‰å…¥æ‰€æœ‰å»ºæ¡ˆåç¨±åˆ°è¨˜æ†¶é«”ï¼ˆç´„ 37K ç­†ï¼Œå¾ˆå¿«ï¼‰"""
        t0 = time.time()
        self._cache = {}
        try:
            conn = sqlite3.connect(self.db_path)
            rows = conn.execute("""
                SELECT community_name,
                       COUNT(*) as tx_count,
                       ROUND(AVG(total_price)) as avg_price,
                       ROUND(AVG(unit_price), 2) as avg_unit,
                       district
                FROM land_transaction
                WHERE community_name IS NOT NULL AND community_name != ''
                GROUP BY community_name
                ORDER BY tx_count DESC
            """).fetchall()
            conn.close()

            for name, cnt, avg_p, avg_u, dist in rows:
                norm = _normalize(name)
                if norm:
                    self._cache[norm] = {
                        "name": name,
                        "tx_count": cnt or 0,
                        "avg_price": avg_p or 0,
                        "avg_unit_price": avg_u or 0,
                        "district": dist or "",
                    }
            elapsed = time.time() - t0
            print(f"ğŸ” CommunityMatcher: {len(self._cache)} å€‹å»ºæ¡ˆè¼‰å…¥ ({elapsed:.2f}s)")
        except Exception as e:
            print(f"âš ï¸ CommunityMatcher è¼‰å…¥å¤±æ•—: {e}")
            self._cache = {}

    def search(self, keyword: str, top_n: int = 20) -> List[Dict]:
        """
        æ¨¡ç³Šæœå°‹å»ºæ¡ˆåç¨±

        å›å‚³ list of dict:
          - name: å»ºæ¡ˆåŸå
          - match_type: ç²¾ç¢º/åŒ…å«/å­åºåˆ—/æ¨¡ç³Š
          - score: åŒ¹é…åˆ†æ•¸ (è¶Šé«˜è¶Šå¥½)
          - tx_count: äº¤æ˜“ç­†æ•¸
          - avg_price: å¹³å‡ç¸½åƒ¹
          - avg_unit_price: å¹³å‡å–®åƒ¹
          - district: è¡Œæ”¿å€
        """
        if not keyword or not keyword.strip():
            return []

        norm_kw = _normalize(keyword)
        if not norm_kw:
            return []

        results = []

        for norm_name, info in self._cache.items():
            score = 0
            match_type = ""

            # 1. ç²¾ç¢ºåŒ¹é…
            if norm_kw == norm_name:
                score = 1000 + info["tx_count"]
                match_type = "ç²¾ç¢º"

            # 2. åŒ…å«åŒ¹é…ï¼ˆquery åŒ…å«åœ¨ name ä¸­ï¼Œæˆ–åå‘ï¼‰
            elif norm_kw in norm_name:
                # query æ˜¯ name çš„å­å­—ä¸²
                ratio = len(norm_kw) / len(norm_name)
                score = 500 + ratio * 200 + min(info["tx_count"], 200) * 0.5
                match_type = "åŒ…å«"
            elif norm_name in norm_kw:
                # name æ˜¯ query çš„å­å­—ä¸²
                ratio = len(norm_name) / len(norm_kw)
                score = 400 + ratio * 200 + min(info["tx_count"], 200) * 0.5
                match_type = "åŒ…å«"

            # 3. å­åºåˆ—åŒ¹é…
            elif len(norm_kw) >= 2 and _is_subsequence(norm_kw, norm_name):
                ratio = len(norm_kw) / len(norm_name)
                score = 200 + ratio * 200 + min(info["tx_count"], 50)
                match_type = "å­åºåˆ—"

            # 4. ç·¨è¼¯è·é›¢æ¨¡ç³ŠåŒ¹é…
            else:
                max_allowed = max(1, len(norm_kw) // 3)
                dist = _edit_distance(norm_kw, norm_name, max_allowed)
                if dist <= max_allowed:
                    score = 100 - dist * 20 + min(info["tx_count"], 30)
                    match_type = "æ¨¡ç³Š"
                else:
                    # 5. å…±åŒå­—å…ƒæ¯”ç‡ (æœ€å¾Œæ‰‹æ®µï¼Œé–€æª»è¼ƒé«˜)
                    cr = _common_chars_ratio(norm_kw, norm_name)
                    if cr >= 0.6 and len(norm_kw) >= 2:
                        score = 50 + cr * 80 + min(info["tx_count"], 20)
                        match_type = "ç›¸ä¼¼"

            if score > 0:
                results.append({
                    "name": info["name"],
                    "match_type": match_type,
                    "score": round(score, 1),
                    "tx_count": info["tx_count"],
                    "avg_price": info["avg_price"],
                    "avg_unit_price": info["avg_unit_price"],
                    "district": info["district"],
                })

        # æ’åºï¼šåˆ†æ•¸é™åº
        results.sort(key=lambda x: -x["score"])
        return results[:top_n]

    def stats(self) -> dict:
        """å›å‚³çµ±è¨ˆè³‡è¨Š"""
        return {
            "total_communities": len(self._cache),
            "db_path": self.db_path,
        }


def fuzzy_search(keyword: str, db_path: str = None, top_n: int = 20) -> List[Dict]:
    """å¿«é€Ÿæ¨¡ç³Šæœå°‹ï¼ˆæ¯æ¬¡å»ºç«‹æ–°é€£ç·šï¼Œé©åˆå–®æ¬¡å‘¼å«ï¼‰"""
    matcher = CommunityMatcher(db_path)
    return matcher.search(keyword, top_n)


# â”€â”€ CLI â”€â”€
if __name__ == "__main__":
    import json
    import sys

    if len(sys.argv) < 2:
        # äº’å‹•æ¨¡å¼
        matcher = CommunityMatcher()
        print(f"\nå»ºæ¡ˆæ¨¡ç³Šæœå°‹å¼•æ“ ({matcher.stats()['total_communities']} å€‹å»ºæ¡ˆ)")
        print("è¼¸å…¥å»ºæ¡ˆåç¨±é—œéµå­—ï¼Œè¼¸å…¥ q é›¢é–‹\n")
        while True:
            kw = input("æœå°‹> ").strip()
            if kw.lower() in ('q', 'quit', 'exit'):
                break
            if not kw:
                continue
            t0 = time.time()
            results = matcher.search(kw)
            elapsed = time.time() - t0
            print(f"\næ‰¾åˆ° {len(results)} å€‹çµæœ ({elapsed*1000:.1f}ms):")
            for i, r in enumerate(results, 1):
                price_wan = r["avg_price"] / 10000 if r["avg_price"] else 0
                unit_wan = r["avg_unit_price"] * 3.30579 / 10000 if r["avg_unit_price"] else 0
                print(f"  {i:2d}. [{r['match_type']}] {r['name']}"
                      f"  ({r['tx_count']}ç­†, å‡{price_wan:.0f}è¬, "
                      f"å‡{unit_wan:.1f}è¬/åª) "
                      f"[{r['district']}] score={r['score']}")
            print()
    else:
        keyword = " ".join(sys.argv[1:])
        matcher = CommunityMatcher()
        results = matcher.search(keyword)
        print(json.dumps(results, ensure_ascii=False, indent=2))
