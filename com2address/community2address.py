#!/usr/bin/env python3
"""
community2address.py - ç¤¾å€/å»ºæ¡ˆåç¨±â†’åœ°å€ç¯„åœ æŸ¥è©¢å·¥å…·

åŠŸèƒ½èˆ‡ address2community.py å®Œå…¨ç›¸åï¼š
  - è¼¸å…¥å»ºæ¡ˆåç¨±ï¼Œè¼¸å‡ºè©²å»ºæ¡ˆå°æ‡‰çš„åœ°å€ç¯„åœ
  - ä¾‹å¦‚: å¥å®‰æ–°åŸFå€ â†’ ä¸‰æ°‘è·¯29å··1ã€3ã€5ã€7è™Ÿ

è³‡æ–™ä¾†æºï¼š
  1. land_data.db (SQLite è³‡æ–™åº«ï¼Œå« land_transaction è¡¨)
  2. manual_mapping.csv (æ‰‹å‹•æ–°å¢çš„å°ç…§)
  3. 591.com.tw APIï¼ˆç·šä¸Šå‚™æ´ï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
  1. å‘½ä»¤åˆ—ï¼š  python3 community2address.py "å¥å®‰æ–°åŸFå€"
  2. äº’å‹•ï¼š    python3 community2address.py
  3. JSONï¼š    python3 community2address.py -j "éƒ½å»³å¤§é™¢"
  4. æ¨¡çµ„ï¼š    from community2address import lookup
              result = lookup("å¥å®‰æ–°åŸFå€")
"""

import csv
import json
import re
import sqlite3
import sys
import time
import threading
from pathlib import Path
from collections import defaultdict
from typing import Optional, Dict, List

# ========== è·¯å¾‘è¨­å®š ==========
SCRIPT_DIR = Path(__file__).parent
LAND_DIR = SCRIPT_DIR.parent
DB_PATH = LAND_DIR / "db" / "land_data.db"
MANUAL_CSV = LAND_DIR / "db" / "manual_mapping.csv"

# ========== å…±ç”¨æ¨¡çµ„ ==========
sys.path.insert(0, str(LAND_DIR))
from address_utils import (
    fullwidth_to_halfwidth,
    normalize_community_name, strip_city_district,
    extract_road_alley, extract_house_number,
    CITIES,
)
from api591 import Api591Client

# ========== ç›¸å®¹æ€§åˆ¥å ==========
extract_number = extract_house_number


def format_address_range(addresses: list, raw_addresses: list = None) -> dict:
    """
    å°‡åœ°å€åˆ—è¡¨æ ¼å¼åŒ–ç‚ºåœ°å€ç¯„åœæ‘˜è¦
    
    å›å‚³:
    {
        "summary": "ä¸‰æ°‘è·¯29å··1ã€3ã€5ã€7è™Ÿ",
        "road_groups": [
            {"road": "ä¸‰æ°‘è·¯29å··", "numbers": [1, 3, 5, 7], "formatted": "ä¸‰æ°‘è·¯29å··1ã€3ã€5ã€7è™Ÿ"}
        ],
        "total_addresses": 4,
        "raw_addresses": [...]
    }
    """
    if not addresses:
        return {
            "summary": "ç„¡åœ°å€è³‡æ–™",
            "road_groups": [],
            "total_addresses": 0,
            "raw_addresses": raw_addresses or [],
        }

    # æ­¸é¡: road_alley â†’ list of (é–€ç‰Œè™Ÿç¢¼, å®Œæ•´åœ°å€)
    INTERSECTION_KEYWORDS = ('å£', 'æ—', 'å°é¢', 'é™„è¿‘', 'å’Œ', 'èˆ‡', 'åŠ', 'äº¤å‰')
    road_map = defaultdict(list)
    ungrouped = []

    for addr in addresses:
        road = extract_road_alley(addr)
        num = extract_number(addr)
        if road and num > 0:
            road_map[road].append((num, addr))
        else:
            ungrouped.append(addr)

    # ç„¡é–€ç‰Œè™Ÿç¢¼çš„åœ°å€ï¼šåªæœ‰ç•¶è·¯æ®µå°šæœªè¢«æœ‰è™Ÿç¢¼çš„åœ°å€ä½¿ç”¨æ™‚ï¼Œæ‰å»ºç«‹ç©ºç¾¤çµ„
    # æ’é™¤è·¯å£/äº¤å‰ç­‰éé–€ç‰Œåœ°å€ï¼ˆè®“å®ƒå€‘é€²å…¥ truly_ungroupedï¼‰
    for addr in ungrouped:
        road = extract_road_alley(addr)
        is_intersection = any(kw in addr for kw in INTERSECTION_KEYWORDS)
        if road and road not in road_map and not is_intersection:
            road_map[road] = []

    road_groups = []
    for road, items in sorted(road_map.items()):
        numbers = sorted(set(num for num, _ in items)) if items else []
        if not numbers:
            road_groups.append({
                "road": road,
                "numbers": [],
                "formatted": f"{road}ï¼ˆç„¡é–€ç‰Œè™Ÿç¢¼ï¼‰",
                "count": 0,
            })
        elif len(numbers) <= 10:
            num_str = "ã€".join(str(n) for n in numbers) + "è™Ÿ"
            road_groups.append({
                "road": road,
                "numbers": numbers,
                "formatted": f"{road}{num_str}",
                "count": len(numbers),
            })
        else:
            num_str = f"{numbers[0]}ï½{numbers[-1]}è™Ÿï¼ˆå…±{len(numbers)}å€‹é–€ç‰Œï¼‰"
            road_groups.append({
                "road": road,
                "numbers": numbers,
                "formatted": f"{road}{num_str}",
                "count": len(numbers),
            })

    # æ’åºï¼šæœ‰é–€ç‰Œçš„æ’å‰é¢ã€äº¤æ˜“æœ€å¤šçš„è·¯æ®µæ’å‰é¢
    road_groups.sort(key=lambda x: (-x["count"]))

    # ç„¡æ³•æ­¸é¡çš„åœ°å€ï¼ˆæˆ–å«äº¤å‰è·¯å£é—œéµå­—çš„åœ°å€ï¼‰
    INTERSECTION_KEYWORDS = ('è·¯å£', 'äº¤å‰', 'æ—', 'å°é¢', 'å’Œ', 'èˆ‡', 'åŠ')
    truly_ungrouped = []
    for a in ungrouped:
        road = extract_road_alley(a)
        if not road or any(kw in a for kw in INTERSECTION_KEYWORDS):
            truly_ungrouped.append(strip_city_district(a) or a)

    # çµ„åˆæ‘˜è¦
    summaries = [g["formatted"] for g in road_groups[:5]]
    # äº¤å‰è·¯å£ç­‰éæ¨™æº–åœ°å€ç›´æ¥é¡¯ç¤ºï¼ˆå»é‡ï¼‰
    seen_misc = set()
    for a in truly_ungrouped:
        if a not in seen_misc:
            summaries.append(a)
            seen_misc.add(a)
    if len(road_groups) > 5:
        summaries.append(f"...é‚„æœ‰ {len(road_groups) - 5} æ¢è·¯æ®µ")

    return {
        "summary": "ï¼›".join(summaries),
        "road_groups": road_groups,
        "total_addresses": len(addresses),
        "raw_addresses": raw_addresses or addresses,
    }




# ========== æ ¸å¿ƒæŸ¥è©¢å¼•æ“ ==========

class Community2AddressLookup:
    """ç¤¾å€/å»ºæ¡ˆåç¨±â†’åœ°å€ç¯„åœ æŸ¥è©¢å¼•æ“ï¼ˆSQLite + 591 APIï¼‰"""

    def __init__(self, verbose: bool = False, use_591: bool = True):
        """
        åˆå§‹åŒ–æŸ¥è©¢å¼•æ“

        Args:
            verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°éç¨‹
            use_591: æ˜¯å¦å•Ÿç”¨ 591 API è£œå……ï¼ˆæœ¬åœ°æ‰¾ä¸åˆ°æ™‚è‡ªå‹•å‘¼å«ï¼‰
        """
        self.verbose = verbose
        self.use_591 = use_591

        # å»ºæ¡ˆåç¨±â†’åœ°å€åˆ—è¡¨ (ä¾†æº: manual_mapping.csv, å°é‡è³‡æ–™ç›´æ¥è¼‰å…¥)
        self._com_to_addr_manual = defaultdict(list)
        # å»ºæ¡ˆåç¨±â†’å€åŸŸè³‡è¨Š (è¼•é‡å¿«å–ï¼ŒæŒ‰éœ€è¼‰å…¥)
        self._com_info = {}
        # æ‰€æœ‰å»ºæ¡ˆåç¨±ï¼ˆæ­£è¦åŒ–ï¼‰
        self._all_names = set()
        # æ­£è¦åŒ–åç¨±â†’åŸå§‹åç¨±æ˜ å°„
        self._norm_to_original = {}
        # DB æŒä¹…é€£ç·šï¼ˆç”¨æ–¼ on-demand æŸ¥è©¢ï¼‰
        self._conn = None
        # ç·šç¨‹é–ï¼ˆç”¨æ–¼ä¿è­·å…±äº«é€£ç·šï¼‰
        self._conn_lock = threading.Lock()

        self._load_data()

        # 591 API clientï¼ˆå»¶é²åˆå§‹åŒ–ï¼Œç¬¬ä¸€æ¬¡æŸ¥è©¢æ™‚æ‰å»ºç«‹ï¼‰
        self._api591 = None

    def _load_data(self):
        """è¼‰å…¥å»ºæ¡ˆåç¨±ç´¢å¼•ï¼ˆè¼•é‡å•Ÿå‹•ï¼Œä¸è¼‰å…¥åœ°å€ï¼‰"""
        t0 = time.time()
        self._load_name_index()
        self._load_manual_csv()
        elapsed = time.time() - t0

        total_communities = len(self._all_names)
        print(f"  âœ… com2address: å·²ç´¢å¼• {total_communities:,} å€‹å»ºæ¡ˆ ({elapsed:.2f}s)")

    def _load_name_index(self):
        """å¾ land_data.db åƒ…è¼‰å…¥å»ºæ¡ˆåç¨±ï¼ˆä¸è¼‰å…¥è³‡è¨Šï¼Œå•Ÿå‹•æ¥µå¿« ~60msï¼‰"""
        if not DB_PATH.exists():
            print(f"âš ï¸  è³‡æ–™åº«ä¸å­˜åœ¨: {DB_PATH}")
            return

        # å…è¨±è·¨ç·šç¨‹ä½¿ç”¨ï¼ˆFlask å¤šç·šç¨‹ç’°å¢ƒï¼‰
        self._conn = sqlite3.connect(str(DB_PATH), check_same_thread=False)
        self._conn.execute("PRAGMA journal_mode=WAL")
        self._conn.execute("PRAGMA cache_size=-64000")
        self._conn.execute("PRAGMA mmap_size=268435456")
        # ç”¨æ–¼ä¿è­·å…±äº«é€£ç·šçš„é–
        self._conn_lock = threading.Lock()

        # åªè¼‰å…¥ DISTINCT å»ºæ¡ˆåç¨±ï¼ˆåˆ©ç”¨ community_name ç´¢å¼•ï¼Œ~60msï¼‰
        cursor = self._conn.execute("""
            SELECT DISTINCT community_name
            FROM land_transaction
            WHERE community_name IS NOT NULL AND community_name != ''
        """)

        for (community,) in cursor:
            community = community.strip()
            if not community:
                continue

            norm_name = normalize_community_name(community)
            self._all_names.add(norm_name)
            self._norm_to_original.setdefault(norm_name, community)

        print(f"  âœ… DB åç¨±ç´¢å¼•: {len(self._all_names):,} å€‹å»ºæ¡ˆ")

    def _get_com_info(self, norm_name: str) -> dict:
        """æŒ‰éœ€æŸ¥è©¢å»ºæ¡ˆåŸºæœ¬è³‡è¨Šï¼ˆä½¿ç”¨ç´¢å¼•ï¼Œ<5msï¼‰"""
        if norm_name in self._com_info:
            return self._com_info[norm_name]

        if not self._conn:
            return {'district': '', 'city': '', 'source': '', 'tx_count': 0}

        original_name = self._norm_to_original.get(norm_name, norm_name)
        with self._conn_lock:
            row = self._conn.execute("""
                SELECT MIN(district) as district, MIN(county_city) as city, COUNT(*) as tx_count
                FROM land_transaction
                WHERE community_name = ?
            """, (original_name,)).fetchone()

        if row:
            info = {
                'district': (row[0] or '').strip(),
                'city': (row[1] or '').strip(),
                'source': 'land_data.db',
                'tx_count': row[2] or 0,
            }
        else:
            info = {'district': '', 'city': '', 'source': '', 'tx_count': 0}

        self._com_info[norm_name] = info
        return info

    def _load_manual_csv(self):
        """å¾ manual_mapping.csv è¼‰å…¥"""
        if not MANUAL_CSV.exists():
            return

        with open(MANUAL_CSV, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                community = row.get('ç¤¾å€åç¨±', '').strip()
                addr = row.get('åœ°å€', '').strip()
                district = row.get('é„‰é®å¸‚å€', '').strip()

                if not community or not addr:
                    continue

                norm_name = normalize_community_name(community)
                self._com_to_addr_manual[norm_name].append(addr)
                self._all_names.add(norm_name)
                self._norm_to_original.setdefault(norm_name, community)
                if norm_name not in self._com_info:
                    self._com_info[norm_name] = {
                        'district': district,
                        'city': '',
                        'source': 'æ‰‹å‹•',
                        'tx_count': 0,
                    }

    def _fuzzy_match(self, keyword: str, top_n: int = 10) -> list:
        """æ¨¡ç³ŠåŒ¹é…å»ºæ¡ˆåç¨±ï¼ˆoptimized: å…ˆåšå¿«é€Ÿç¯©é¸å†ç²¾ç¢ºè©•åˆ†ï¼‰"""
        norm_kw = normalize_community_name(keyword)
        if not norm_kw:
            return []

        matches = []
        kw_set = set(norm_kw)  # ç”¨æ–¼å¿«é€Ÿå­—å…ƒäº¤é›†ç¯©é¸

        for name in self._all_names:
            score = 0
            # å®Œå…¨åŒ¹é…
            if name == norm_kw:
                score = 100
            # åŒ…å«åŒ¹é…ï¼ˆé—œéµå­—æ˜¯å»ºæ¡ˆåçš„å­å­—ä¸²ï¼‰
            elif norm_kw in name:
                ratio = len(norm_kw) / max(len(name), 1)
                score = int(70 + ratio * 15)  # 70~85
            # åŒ…å«åŒ¹é…ï¼ˆå»ºæ¡ˆåæ˜¯é—œéµå­—çš„å­å­—ä¸²ï¼‰
            elif name in norm_kw:
                ratio = len(name) / max(len(norm_kw), 1)
                score = int(60 + ratio * 10)  # 60~70
            # å¿«é€Ÿå­—å…ƒäº¤é›†ç¯©é¸ï¼ˆé¿å…æ˜‚è²´çš„ Counter è¨ˆç®—ï¼‰
            elif len(kw_set & set(name)) / max(len(norm_kw), 1) >= 0.55:
                from collections import Counter
                kw_cnt = Counter(norm_kw)
                name_cnt = Counter(name)
                common = sum(min(kw_cnt[c], name_cnt[c]) for c in kw_cnt)
                ratio = common / max(len(norm_kw), 1)
                if ratio >= 0.55:
                    score = int(ratio * 55)

            if score > 0:
                info = self._get_com_info(name)
                matches.append({
                    'name': self._norm_to_original.get(name, name),
                    'norm_name': name,
                    'score': score,
                    'district': info.get('district', ''),
                    'tx_count': info.get('tx_count', 0),
                })

        # æ’åº: åˆ†æ•¸ â†’ äº¤æ˜“æ•¸
        matches.sort(key=lambda x: (-x['score'], -x['tx_count']))
        return matches[:top_n]

    def _query_db_addresses(self, community_name: str) -> list:
        """å¾ DB æŒ‰éœ€æŸ¥è©¢å»ºæ¡ˆå°æ‡‰çš„åœ°å€ï¼ˆä½¿ç”¨ community_name ç´¢å¼•ï¼Œ<5msï¼‰"""
        if not self._conn:
            return []
        with self._conn_lock:
            rows = self._conn.execute("""
                SELECT DISTINCT address
                FROM land_transaction
                WHERE community_name = ? AND address IS NOT NULL AND address != ''
            """, (community_name,)).fetchall()
        return [r[0].strip() for r in rows if r[0]]

    def query(self, community_name: str, top_n: int = 5, use_591: bool = None) -> dict:
        """
        æŸ¥è©¢å»ºæ¡ˆåç¨±å°æ‡‰çš„åœ°å€ç¯„åœ

        æŸ¥è©¢é †åºï¼šæœ¬åœ°ç²¾ç¢º â†’ æœ¬åœ°æ¨¡ç³Š â†’ 591 API å‚™æ´ï¼ˆæœ¬åœ°å®Œå…¨æ‰¾ä¸åˆ°æ™‚ï¼‰
        ä½¿ç”¨ç´¢å¼•æŸ¥è©¢ï¼Œæ¯«ç§’ç´šå›æ‡‰ã€‚
        """
        enable_591 = use_591 if use_591 is not None else self.use_591
        norm_name = normalize_community_name(community_name)

        if self.verbose:
            print(f"  ğŸ” æŸ¥è©¢å»ºæ¡ˆ: {community_name}")
            print(f"     æ­£è¦åŒ–: {norm_name}")

        addresses = []
        raw_addresses = []
        match_type = None
        matched_name = norm_name
        district = ''
        city = ''

        # === ç¬¬ 1 å±¤ï¼šç²¾ç¢ºåŒ¹é…ï¼ˆç´¢å¼•æŸ¥è©¢ï¼‰ ===
        if norm_name in self._all_names:
            match_type = "ç²¾ç¢ºåŒ¹é…"
            original_name = self._norm_to_original.get(norm_name, community_name)
            # å¾ DB on-demand æŸ¥è©¢åœ°å€ï¼ˆåˆ©ç”¨ community_name ç´¢å¼•ï¼‰
            db_addrs = self._query_db_addresses(original_name)
            manual_addrs = self._com_to_addr_manual.get(norm_name, [])
            raw_addresses = list(set(db_addrs + manual_addrs))
            addresses = raw_addresses
            if self.verbose:
                print(f"     âœ… Level 1: ç²¾ç¢ºåŒ¹é…, {len(addresses)} å€‹åœ°å€")

        # === ç¬¬ 2 å±¤ï¼šæ¨¡ç³ŠåŒ¹é… ===
        if match_type is None:
            fuzzy_results = self._fuzzy_match(norm_name, top_n=5)
            if fuzzy_results and fuzzy_results[0]['score'] >= 50:
                best = fuzzy_results[0]
                matched_name = best['norm_name']
                match_type = f"æ¨¡ç³ŠåŒ¹é… ({best['score']}%)"
                original_name = self._norm_to_original.get(matched_name, best['name'])
                db_addrs = self._query_db_addresses(original_name)
                manual_addrs = self._com_to_addr_manual.get(matched_name, [])
                raw_addresses = list(set(db_addrs + manual_addrs))
                addresses = raw_addresses
                if self.verbose:
                    print(f"     âœ… Level 2: æ¨¡ç³ŠåŒ¹é… {best['name']} ({best['score']}%)")

        # === ç¬¬ 3 å±¤ï¼š591 API å‚™æ´ï¼ˆæœ¬åœ°å®Œå…¨æ‰¾ä¸åˆ°æ™‚ï¼‰ ===
        if match_type is None and enable_591:
            if self.verbose:
                print(f"     ğŸŒ Level 3: å‘¼å« 591 API...")
            api_result = self._query_591_fallback(community_name)
            if api_result:
                match_type = "591 API"
                matched_name = normalize_community_name(api_result.get('name', community_name))
                addresses = api_result.get('addresses', [])
                raw_addresses = addresses
                district = api_result.get('district', '')
                if self.verbose:
                    print(f"     âœ… 591 æ‰¾åˆ°: {api_result.get('name')} | {addresses}")
                # å„²å­˜åˆ°è¨˜æ†¶é«”å’Œ manual_mapping.csvï¼ˆä¸‹æ¬¡ç›´æ¥æœ¬åœ°å‘½ä¸­ï¼‰
                self._persist_591_result(community_name, api_result)

        # === æ ¼å¼åŒ– ===
        # ç”¨ DB æ“´å±•åœ°å€ï¼ˆå¾ä»£è¡¨åœ°å€æ‰¾å‡ºåŒç¤¾å€æ‰€æœ‰é–€ç‰Œè™Ÿï¼‰
        unique_addrs = list(set(addresses))
        info = self._get_com_info(matched_name)
        if not district:
            district = info.get('district', '')
        if not city:
            city = info.get('city', '')
        expanded = self._expand_addresses_from_db(unique_addrs, district)
        if expanded:
            unique_addrs = expanded
            if self.verbose:
                print(f"     ğŸ“ DB æ“´å±•: {len(addresses)} â†’ {len(unique_addrs)} å€‹åœ°å€")
        address_range = format_address_range(unique_addrs, raw_addresses or unique_addrs)

        candidates = self._fuzzy_match(norm_name, top_n=top_n)

        return {
            'input': community_name,
            'matched_name': self._norm_to_original.get(matched_name, matched_name),
            'match_type': match_type or "æœªæ‰¾åˆ°",
            'district': district,
            'city': city,
            'transaction_count': info.get('tx_count', 0),
            'address_range': address_range,
            'candidates': candidates,
            'found': match_type is not None,
        }

    def _expand_addresses_from_db(self, addresses: list, district: str = '') -> list:
        """
        å¾ä»£è¡¨åœ°å€æ“´å±•å‡ºåŒç¤¾å€çš„æ‰€æœ‰é–€ç‰Œè™Ÿã€‚
        ä½¿ç”¨æŒä¹…é€£ç·šå’Œç´¢å¼•æŸ¥è©¢ã€‚
        """
        if not addresses or not self._conn:
            return []

        expanded = set()
        conn = self._conn
        for addr in addresses:
            s = strip_city_district(addr)

            # è§£æ street (è·¯/è¡—/å¤§é“) å’Œ lane (å··)
            m = re.search(r'([ä¸€-é¿¿]+?(?:è·¯|è¡—|å¤§é“)(?:[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+æ®µ)?)', s)
            if not m:
                expanded.add(addr)
                continue
            street = m.group(1)
            lane_m = re.search(r'(\d+)å··', s)
            lane = lane_m.group(1) if lane_m else ''

            # é–€ç‰Œè™Ÿ
            num_m = re.search(r'(\d+)è™Ÿ', s)
            if not num_m:
                expanded.add(addr)
                continue
            ref_number = num_m.group(1)

            # æ‰¾ districtï¼ˆè‹¥æœªæä¾›ï¼Œå¾åŸå§‹åœ°å€è§£æï¼‰
            addr_district = district
            if not addr_district:
                raw = fullwidth_to_halfwidth(str(addr).strip())
                for c in CITIES:
                    if raw.startswith(c):
                        raw = raw[len(c):]
                        dm = re.match(r'([\u4e00-\u9fff]{1,3}[å€é®é„‰å¸‚])', raw)
                        if dm:
                            addr_district = dm.group(1)
                        break

            if not addr_district:
                expanded.add(addr)
                continue

            # å¾ DB å–å¾—ä»£è¡¨åœ°å€çš„å»ºç‰©ç‰¹å¾µï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
            rows = conn.execute("""
                SELECT total_floors, build_date FROM land_transaction
                WHERE street=? AND lane=? AND number=? AND district=?
                LIMIT 1
            """, (street, lane, ref_number, addr_district)).fetchall()

            if not rows:
                expanded.add(addr)
                continue

            total_floors, build_date = rows[0]

            # æ‰¾åŒç¤¾å€æ‰€æœ‰é–€ç‰Œè™Ÿï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
            all_numbers = conn.execute("""
                SELECT DISTINCT CAST(number AS INTEGER) as num
                FROM land_transaction
                WHERE street=? AND lane=? AND district=?
                  AND total_floors=? AND build_date=?
                  AND number IS NOT NULL AND number != ''
                ORDER BY num
            """, (street, lane, addr_district,
                  total_floors, build_date)).fetchall()

            if all_numbers:
                road = street + (f"{lane}å··" if lane else "")
                for (num,) in all_numbers:
                    expanded.add(f"{road}{num}è™Ÿ")
            else:
                expanded.add(addr)

        return list(expanded) if expanded else []

    def _query_591_fallback(self, community_name: str) -> dict:
        """
        591 API å‚™æ´æŸ¥è©¢ï¼ˆæœ¬åœ°å®Œå…¨æ‰¾ä¸åˆ°æ™‚å‘¼å«ï¼‰
        å›å‚³ {name, addresses, district} æˆ– None
        """
        try:
            if self._api591 is None:
                self._api591 = Api591Client()

            item = self._api591.search_by_name(community_name)
            if item:
                address = item.get('address', '')
                return {
                    'name': item.get('name', community_name),
                    'addresses': [address] if address else [],
                    'district': item.get('section', ''),
                }
        except Exception as e:
            if self.verbose:
                print(f"  âš ï¸  591 API éŒ¯èª¤: {e}")
        return None

    def _persist_591_result(self, original_query: str, api_result: dict):
        """å°‡ 591 æŸ¥è©¢çµæœå­˜å…¥è¨˜æ†¶é«”å’Œ manual_mapping.csvï¼ˆé¿å…é‡è¤‡ API å‘¼å«ï¼‰"""
        name = api_result.get('name', original_query)
        addresses = api_result.get('addresses', [])
        district = api_result.get('district', '')
        if not addresses:
            return

        norm = normalize_community_name(name)

        # æ›´æ–°è¨˜æ†¶é«”
        for addr in addresses:
            if addr not in self._com_to_addr_manual[norm]:
                self._com_to_addr_manual[norm].append(addr)
        self._all_names.add(norm)
        self._norm_to_original.setdefault(norm, name)
        if norm not in self._com_info:
            self._com_info[norm] = {
                'district': district, 'city': '', 'source': '591_API', 'tx_count': 0
            }

        # å¯«å…¥ manual_mapping.csv
        file_exists = MANUAL_CSV.exists()
        try:
            with open(MANUAL_CSV, 'a', encoding='utf-8', newline='') as f:
                writer = csv.writer(f)
                if not file_exists:
                    writer.writerow(['åœ°å€', 'ç¤¾å€åç¨±', 'é„‰é®å¸‚å€', 'å‚™è¨»'])
                for addr in addresses:
                    writer.writerow([addr, name, district, '591_API'])
            if self.verbose:
                print(f"  ğŸ’¾ å·²å­˜å…¥ manual_mapping.csv: {name} â†’ {addresses}")
        except Exception as e:
            if self.verbose:
                print(f"  âš ï¸  å„²å­˜å¤±æ•—: {e}")

    def close(self):
        """é—œé–‰è³‡æ–™åº«é€£ç·š"""
        if self._conn:
            self._conn.close()
            self._conn = None

    def __del__(self):
        self.close()

    def search(self, keyword: str, limit: int = 20) -> list:
        """æœå°‹å»ºæ¡ˆåç¨±ï¼ˆç”¨æ–¼è‡ªå‹•å®Œæˆï¼‰"""
        return self._fuzzy_match(keyword, top_n=limit)

    def stats(self) -> dict:
        """çµ±è¨ˆè³‡è¨Š"""
        return {
            'total_communities': len(self._all_names),
            'db_communities': len([n for n in self._all_names if n not in self._com_to_addr_manual]),
            'manual_communities': len(self._com_to_addr_manual),
        }


# ========== ä¾¿åˆ©å‡½å¼ ==========

_global_lookup = None


def lookup(community_name: str, **kwargs) -> dict:
    """ä¾¿åˆ©æŸ¥è©¢å‡½å¼"""
    global _global_lookup
    if _global_lookup is None:
        _global_lookup = Community2AddressLookup(**kwargs)
    return _global_lookup.query(community_name)


def quick_lookup(community_name: str) -> str:
    """æœ€ç°¡æŸ¥è©¢ï¼Œå›å‚³åœ°å€æ‘˜è¦"""
    result = lookup(community_name)
    if result['found']:
        return result['address_range']['summary']
    return "æœªæ‰¾åˆ°"


# ========== CLI ==========

def print_result(result: dict, show_detail: bool = False):
    """æ ¼å¼åŒ–è¼¸å‡º"""
    name = result['input']
    found = result['found']

    if found:
        matched = result['matched_name']
        match_type = result['match_type']
        addr_range = result['address_range']
        district = result['district']
        tx_count = result['transaction_count']

        print(f"\nğŸ˜ï¸  {name}")
        if matched != name:
            print(f"   â†’ åŒ¹é…: {matched} ({match_type})")
        else:
            print(f"   â†’ {match_type}")

        if district:
            print(f"   ğŸ“ å€åŸŸ: {district}")
        if tx_count:
            print(f"   ğŸ“Š äº¤æ˜“ç­†æ•¸: {tx_count:,}")

        print(f"   ğŸ“¬ åœ°å€æ•¸: {addr_range['total_addresses']}")
        print()

        # è¼¸å‡ºè·¯æ®µåˆ†çµ„
        for g in addr_range['road_groups'][:8]:
            print(f"   ğŸ  {g['formatted']}")

        if len(addr_range['road_groups']) > 8:
            remaining = len(addr_range['road_groups']) - 8
            print(f"   ... é‚„æœ‰ {remaining} æ¢è·¯æ®µ")

        if show_detail:
            print(f"\n   === æ‰€æœ‰åŸå§‹åœ°å€ ===")
            for i, addr in enumerate(sorted(set(addr_range['raw_addresses']))[:30], 1):
                print(f"   {i:3d}. {addr}")
            if len(addr_range['raw_addresses']) > 30:
                print(f"   ... å…± {len(addr_range['raw_addresses'])} ç­†")
    else:
        print(f"\nğŸ˜ï¸  {name}")
        print(f"   â†’ â“ æœªæ‰¾åˆ°")

        # é¡¯ç¤ºå€™é¸
        if result['candidates']:
            print(f"\n   ğŸ’¡ ä½ å¯èƒ½åœ¨æ‰¾ï¼š")
            for c in result['candidates'][:5]:
                print(f"   â€¢ {c['name']} ({c['district']}, {c['tx_count']}ç­†)")


def interactive_mode(engine: Community2AddressLookup):
    """äº’å‹•æ¨¡å¼"""
    stats = engine.stats()
    print("=" * 60)
    print("ğŸ˜ï¸  å»ºæ¡ˆåç¨±â†’åœ°å€ç¯„åœ æŸ¥è©¢å·¥å…· (com2address)")
    print("=" * 60)
    print(f"ğŸ“Š å»ºæ¡ˆæ•¸: {stats['total_communities']:,}")
    print("-" * 60)
    print("è¼¸å…¥å»ºæ¡ˆåç¨±æŸ¥è©¢ï¼Œ'q' é€€å‡ºï¼Œ'detail' è©³ç´°æ¨¡å¼")
    print("-" * 60)

    show_detail = False

    while True:
        try:
            name = input("\nğŸ” å»ºæ¡ˆåç¨±: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ å†è¦‹ï¼")
            break

        if not name:
            continue
        if name.lower() in ("q", "quit", "exit"):
            print("ğŸ‘‹ å†è¦‹ï¼")
            break
        if name.lower() == "detail":
            show_detail = not show_detail
            print(f"   è©³ç´°æ¨¡å¼: {'é–‹å•Ÿ' if show_detail else 'é—œé–‰'}")
            continue
        if name.lower() == "stats":
            s = engine.stats()
            print(f"   å»ºæ¡ˆæ•¸: {s['total_communities']:,}")
            continue

        t0 = time.time()
        result = engine.query(name)
        elapsed = time.time() - t0
        print_result(result, show_detail)
        print(f"   â±ï¸  {elapsed:.3f}s")


def main():
    import argparse
    parser = argparse.ArgumentParser(
        description="ç¤¾å€/å»ºæ¡ˆåç¨±â†’åœ°å€ç¯„åœ æŸ¥è©¢å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹ï¼š
  python3 community2address.py "å¥å®‰æ–°åŸAå€"
  python3 community2address.py "å¥å®‰æ–°åŸFå€"
  python3 community2address.py "éƒ½å»³å¤§é™¢"
  python3 community2address.py --detail "ä»æ„›å¸å¯¶"
  python3 community2address.py -j "ä¿¡ç¾©æ˜Ÿæ± "
  python3 community2address.py --search "å¥å®‰"
  python3 community2address.py --no-591 "å»ºæ¡ˆåç¨±"   (é›¢ç·šæ¨¡å¼ï¼Œåœç”¨ 591 API)
        """,
    )
    parser.add_argument("name", nargs="*", help="å»ºæ¡ˆåç¨±")
    parser.add_argument("--detail", "-d", action="store_true", help="é¡¯ç¤ºè©³ç´°åœ°å€")
    parser.add_argument("--verbose", "-v", action="store_true", help="é¡¯ç¤ºè©³ç´°éç¨‹")
    parser.add_argument("--json", "-j", action="store_true", help="JSON è¼¸å‡º")
    parser.add_argument("--search", "-s", help="æœå°‹å»ºæ¡ˆåç¨±")
    parser.add_argument("--no-591", action="store_true", help="åœç”¨ 591 APIï¼ˆé›¢ç·šæ¨¡å¼ï¼‰")
    # å‘ä¸‹ç›¸å®¹èˆŠçš„ --with-591 æ——æ¨™ï¼ˆå·²å»¢æ£„ï¼Œ591 é è¨­ç‚ºå•Ÿç”¨ï¼‰
    parser.add_argument("--with-591", action="store_true", help=argparse.SUPPRESS)

    args = parser.parse_args()
    use_591 = not args.no_591

    engine = Community2AddressLookup(verbose=args.verbose, use_591=use_591)

    if args.search:
        results = engine.search(args.search, limit=20)
        if args.json:
            print(json.dumps(results, ensure_ascii=False, indent=2))
        else:
            print(f"\nğŸ” æœå°‹ã€Œ{args.search}ã€æ‰¾åˆ° {len(results)} å€‹å»ºæ¡ˆï¼š")
            for r in results:
                print(f"  â€¢ {r['name']} ({r['district']}, {r['tx_count']}ç­†, ç›¸ä¼¼åº¦:{r['score']}%)")
        return

    if args.name:
        for name in args.name:
            t0 = time.time()
            result = engine.query(name)
            elapsed = time.time() - t0
            if args.json:
                print(json.dumps(result, ensure_ascii=False, indent=2))
            else:
                print_result(result, args.detail)
                if args.verbose:
                    print(f"   â±ï¸  {elapsed:.3f}s")
        return

    interactive_mode(engine)


if __name__ == "__main__":
    main()
