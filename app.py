#!/usr/bin/env python3
"""
è‰¯å¯Œå±…åœ°ç”¢ v3.0 â€” å°ˆæ¥­æˆ¿åœ°ç”¢åœ°åœ–ç³»çµ±
ä¿®æ­£ï¼šå…¨å½¢â†’åŠå½¢ã€ä¸­æ–‡æ¨“å±¤â†’æ•¸å­—ã€åœ°å€æœå°‹ã€ç¯©é¸UXã€å»ºæ¡ˆæ¯”å°ç²¾æº–åŒ–
æŠ€è¡“ï¼šFlask + DuckDB + Leaflet.js + OpenStreetMap
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import duckdb
import os
import re
import json
import math
import time
import hashlib
import threading
from collections import defaultdict
from urllib.parse import quote_plus
from urllib.request import urlopen, Request

app = Flask(__name__)
CORS(app)

# ============================================================
# è¨­å®š
# ============================================================
CSV_PATH = '/home/cyclone/land/ALL_lvr_land_a.csv'
BUILDING_CSV_PATH = '/home/cyclone/land/Building_Projects_B.csv'
GEOCODE_CACHE_PATH = '/home/cyclone/land/geocode_cache.json'
DB_PATH = '/home/cyclone/land/land_data.duckdb'
PING_TO_SQM = 3.30579

# ============================================================
# å…¨åŸŸç‹€æ…‹
# ============================================================
_building_projects = []          # list[dict]  â€” Building_Projects_B
_building_index = {}             # id -> project
_address_index = {}              # id -> {address_raw, address, district}
_geocode_cache = {}
_geocode_lock = threading.Lock()
_data_ready = False
_db = None

# ============================================================
# ç‰¹æ®Šäº¤æ˜“é¡å‹
# ============================================================
SPECIAL_TX_PATTERNS = [
    ('è¦ªå‹ç‰¹æ®Šé—œä¿‚', ['è¦ªå‹', 'ç‰¹æ®Šé—œä¿‚'],              'âš ï¸', '#e74c3c'),
    ('è¦ªç­‰äº¤æ˜“',     ['è¦ªç­‰', 'ç­‰è¦ª'],                  'ğŸ‘¥', '#e67e22'),
    ('é å”®å±‹',       ['é å”®'],                          'ğŸ—', '#3498db'),
    ('å«å¢å»º',       ['å¢å»º'],                          'ğŸ ', '#9b59b6'),
    ('è»Šä½äº¤æ˜“',     ['è»Šä½äº¤æ˜“', 'å–®ç¨è»Šä½'],           'ğŸ…¿', '#607d8b'),
    ('æ³•æ‹',         ['æ‹è³£', 'æ³•æ‹'],                  'âš–', '#c0392b'),
    ('ä¿¡è¨—',         ['ä¿¡è¨—'],                          'ğŸ“‹', '#8e44ad'),
    ('å«è£æ½¢',       ['è£æ½¢'],                          'ğŸ”¨', '#27ae60'),
    ('å‚µå‹™ç›¸é—œ',     ['å‚µ'],                            'ğŸ’°', '#d35400'),
    ('å«é ‚æ¨“åŠ è“‹',   ['é ‚æ¨“'],                          'ğŸ”', '#795548'),
    ('å…±æœ‰',         ['å…±æœ‰'],                          'ğŸ‘«', '#00897b'),
]


def detect_special_transaction(note):
    if not note or not isinstance(note, str):
        return []
    results = []
    for label, keywords, icon, color in SPECIAL_TX_PATTERNS:
        if any(kw in note for kw in keywords):
            results.append({'label': label, 'icon': icon, 'color': color})
    return results


# ============================================================
# æ–‡å­— / æ•¸å­—è½‰æ›å·¥å…·
# ============================================================
def fullwidth_to_halfwidth(text):
    """å…¨å½¢æ•¸å­—ã€è‹±æ–‡å­—æ¯è½‰åŠå½¢"""
    if not text:
        return text
    out = []
    for ch in str(text):
        c = ord(ch)
        if 0xFF10 <= c <= 0xFF19:      # ï¼-ï¼™
            out.append(chr(c - 0xFEE0))
        elif 0xFF21 <= c <= 0xFF3A:    # ï¼¡-ï¼º
            out.append(chr(c - 0xFEE0))
        elif 0xFF41 <= c <= 0xFF5A:    # ï½-ï½š
            out.append(chr(c - 0xFEE0))
        else:
            out.append(ch)
    return ''.join(out)


def halfwidth_to_fullwidth(text):
    """åŠå½¢æ•¸å­—ã€è‹±æ–‡å­—æ¯è½‰å…¨å½¢"""
    if not text:
        return text
    out = []
    for ch in str(text):
        c = ord(ch)
        if 0x30 <= c <= 0x39:          # 0-9
            out.append(chr(c + 0xFEE0))
        elif 0x41 <= c <= 0x5A:        # A-Z
            out.append(chr(c + 0xFEE0))
        elif 0x61 <= c <= 0x7A:        # a-z
            out.append(chr(c + 0xFEE0))
        else:
            out.append(ch)
    return ''.join(out)


_CN = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
       'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9}


def chinese_to_number(text):
    """ä¸­æ–‡æ•¸å­—â†’é˜¿æ‹‰ä¼¯  åä¸€â†’11  äºŒåä¸‰â†’23  ä¸‰åå…«â†’38"""
    if not text:
        return 0
    s = re.sub(r'[å±¤æ¨“Ff\s]', '', str(text).strip())
    if not s:
        return 0
    try:
        return int(s)
    except ValueError:
        pass
    if s == 'å':
        return 10
    if s == 'ç™¾':
        return 100
    if 'ç™¾' in s:
        h_part, rest = s.split('ç™¾', 1)
        h = _CN.get(h_part, 1) if h_part else 1
        return h * 100 + (chinese_to_number(rest) if rest else 0)
    if 'å' in s:
        t_part, o_part = s.split('å', 1)
        tens = _CN.get(t_part, 1) if t_part else 1
        ones = _CN.get(o_part, 0) if o_part else 0
        return tens * 10 + ones
    return _CN.get(s, 0)


def _fmt_one_floor(part):
    """æ ¼å¼åŒ–å–®ä¸€æ¨“å±¤ç‰‡æ®µ"""
    part = part.strip()
    if not part:
        return ''
    bm = re.search(r'åœ°ä¸‹([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾\d]+)', part)
    if bm:
        return f'B{chinese_to_number(bm.group(1))}F'
    fm = re.search(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾\d]+)\s*å±¤', part)
    if fm:
        n = chinese_to_number(fm.group(1))
        extra = re.sub(r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾\d]+\s*å±¤', '', part).strip()
        return f'{n}F' + (f'+{extra}' if extra else '')
    if 'å…¨' in part:
        return 'å…¨æ£Ÿ'
    if 'å¤¾å±¤' in part:
        return 'å¤¾å±¤'
    if 'é ‚' in part:
        return 'é ‚æ¨“'
    return part


def format_floor(floor_str, total_str=None):
    """å®Œæ•´æ¨“å±¤æ ¼å¼åŒ–  'ä¸ƒå±¤'+'åå±¤' â†’ '7F/10F'"""
    if not floor_str or str(floor_str).strip() in ('', 'nan', 'None'):
        return 'â€”'
    s = fullwidth_to_halfwidth(str(floor_str))
    parts = re.split(r'[ï¼Œ,]', s)
    fmts = [_fmt_one_floor(p) for p in parts if p.strip()]
    fmts = [f for f in fmts if f]
    if not fmts:
        return 'â€”'
    result = ','.join(fmts)
    if total_str:
        t = _fmt_total_floors(total_str)
        if t != 'â€”':
            result = f'{result}/{t}'
    return result


def _fmt_total_floors(s):
    if not s or str(s).strip() in ('', 'nan', 'None'):
        return 'â€”'
    s = fullwidth_to_halfwidth(str(s).strip())
    fm = re.search(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾\d]+)\s*å±¤', s)
    if fm:
        return f'{chinese_to_number(fm.group(1))}F'
    try:
        return f'{int(s)}F'
    except ValueError:
        pass
    return s


# ============================================================
# åœ°å€æ¯”å°ï¼šå¾ä»£è¡¨åœ°å€æŠ½å–å¤šå±¤ç´š pattern
# ============================================================
def extract_address_patterns(address):
    """å›å‚³ [æœ€ç²¾ç¢º, ..., æœ€å¯¬é¬†] çš„ LIKE pattern åˆ—è¡¨"""
    if not address:
        return []
    addr = fullwidth_to_halfwidth(str(address))
    patterns = []
    # road + section + lane + alley
    m = re.search(
        r'([\u4e00-\u9fff]+(?:è·¯|è¡—|å¤§é“)(?:[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]æ®µ)?\d+å··\d+å¼„)',
        addr)
    if m:
        patterns.append(m.group(1))
    # road + section + lane
    m = re.search(
        r'([\u4e00-\u9fff]+(?:è·¯|è¡—|å¤§é“)(?:[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]æ®µ)?\d+å··)',
        addr)
    if m and m.group(1) not in patterns:
        patterns.append(m.group(1))
    # road + section (æœ‰é–€ç‰Œ)
    m = re.search(
        r'([\u4e00-\u9fff]+(?:è·¯|è¡—|å¤§é“)(?:[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]æ®µ)?)\d+è™Ÿ',
        addr)
    if m and m.group(1) not in patterns:
        patterns.append(m.group(1))
    # road + section only
    m = re.search(
        r'([\u4e00-\u9fff]+(?:è·¯|è¡—|å¤§é“)(?:[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]æ®µ)?)',
        addr)
    if m and m.group(1) not in patterns:
        patterns.append(m.group(1))
    return patterns


def extract_road_name(address):
    pats = extract_address_patterns(address)
    return pats[-1] if pats else None


# ============================================================
# å°ç£é„‰é®å¸‚å€åº§æ¨™
# ============================================================
DISTRICT_COORDINATES = {
    'ä¸­å£¢å€': (24.9696, 120.9843), 'æ¡ƒåœ’å€': (25.0330, 121.3167),
    'æ–°ç«¹å¸‚': (24.8026, 120.9693), 'åŒ—å±¯å€': (24.2169, 120.7901),
    'æ·¡æ°´å€': (25.1654, 121.4529), 'æ¿æ©‹å€': (25.0121, 121.4627),
    'è¥¿å±¯å€': (24.1884, 120.6350), 'æ–°èŠå€': (25.0568, 121.4315),
    'ç«¹åŒ—å¸‚': (24.8363, 120.9863), 'ä¸­å’Œå€': (25.0049, 121.4935),
    'åŒ—æŠ•å€': (25.1370, 121.5130), 'è‹—æ —å¸‚': (24.5595, 120.8196),
    'ä¸­å±±å€': (25.0455, 121.5149), 'å¤§å®‰å€': (25.0330, 121.5254),
    'æ¾å±±å€': (25.0487, 121.5623), 'å—æ¸¯å€': (25.0543, 121.6090),
    'ä¿¡ç¾©å€': (25.0330, 121.5654), 'å…§æ¹–å€': (25.0850, 121.5788),
    'å£«æ—å€': (25.1122, 121.5254), 'å¤§åŒå€': (25.0737, 121.5149),
    'æ–‡å±±å€': (25.0035, 121.5674), 'å—å±¯å€': (24.1003, 120.6684),
    'çƒæ—¥å€': (24.0630, 120.6717), 'é¾äº•å€': (24.2507, 120.5690),
    'éœ§å³°å€': (24.0580, 120.8225), 'å¤ªå¹³å€': (24.1456, 120.9383),
    'æ½­å­å€': (24.1995, 120.8610), 'å¤§é›…å€': (24.2575, 120.7870),
    'ç¥å²¡å€': (24.2456, 120.8080), 'æ¸…æ°´å€': (24.2583, 120.5689),
    'æ¢§æ£²å€': (24.2495, 120.5439), 'å¤§è‚šå€': (24.2250, 120.5519),
    'æ²™é¹¿å€': (24.2330, 120.5699), 'åŸºéš†å¸‚': (25.1276, 121.7347),
    'å®œè˜­ç¸£': (24.7599, 121.7497), 'èŠ±è“®ç¸£': (24.0046, 121.5743),
    'å°æ±ç¸£': (22.7696, 121.1446), 'å±æ±ç¸£': (22.5442, 120.4886),
    'é›²æ—ç¸£': (23.7071, 120.4334), 'å˜‰ç¾©å¸‚': (23.4788, 120.4432),
    'å˜‰ç¾©ç¸£': (23.4534, 120.6081), 'æ–°åŒ—å¸‚': (25.0170, 121.4627),
    'ä¸‰é‡å€': (25.0617, 121.4879), 'è˜†æ´²å€': (25.0855, 121.4738),
    'æ±æ­¢å€': (25.0626, 121.6610), 'æ°¸å’Œå€': (25.0076, 121.5138),
    'ä¸‰å³½å€': (24.9340, 121.3687), 'åœŸåŸå€': (24.9723, 121.4437),
    'é¶¯æ­Œå€': (24.9519, 121.3517), 'æ³°å±±å€': (25.0500, 121.4300),
    'æ—å£å€': (25.0786, 121.3919), 'äº”è‚¡å€': (25.0787, 121.4380),
    'å…«é‡Œå€': (25.1400, 121.4000), 'æ¨¹æ—å€': (24.9909, 121.4200),
    'æ·±å‘å€': (25.0020, 121.6155), 'ç‘èŠ³å€': (25.1092, 121.8100),
    'è¬é‡Œå€': (25.1792, 121.6891), 'é‡‘å±±å€': (25.2220, 121.6370),
    'å·¦ç‡Ÿå€': (22.6847, 120.2940), 'å‰é®å€': (22.5955, 120.3268),
    'ä¸‰æ°‘å€': (22.6467, 120.3165), 'é¼“å±±å€': (22.6555, 120.2710),
    'è‹“é›…å€': (22.6200, 120.3260), 'æ¥ æ¢“å€': (22.7308, 120.3262),
    'å°æ¸¯å€': (22.5647, 120.3456), 'é³³å±±å€': (22.6268, 120.3595),
    'å¤§å¯®å€': (22.5965, 120.3987), 'é³¥æ¾å€': (22.6620, 120.3647),
    'ä»æ­¦å€': (22.7002, 120.3520), 'å²¡å±±å€': (22.7906, 120.2953),
    'è·¯ç«¹å€': (22.8561, 120.2617), 'æ©‹é ­å€': (22.7575, 120.3058),
    'é¾æ½­å€': (24.8642, 121.2163), 'æ¥Šæ¢…å€': (24.9077, 121.1449),
    'å¤§æºªå€': (24.8832, 121.2863), 'è˜†ç«¹å€': (25.0439, 121.2917),
    'å¤§åœ’å€': (25.0647, 121.2333), 'é¾œå±±å€': (25.0287, 121.3453),
    'å…«å¾·å€': (24.9456, 121.2900), 'å¹³é®å€': (24.9459, 121.2182),
    'è§€éŸ³å€': (25.0349, 121.1417), 'æ–°å±‹å€': (24.9736, 121.1067),
    'ç«¹æ±é®': (24.7310, 121.0900), 'æ–°è±é„‰': (24.8900, 120.9700),
    'æ¹–å£é„‰': (24.9023, 121.0400), 'æ°¸åº·å€': (22.9896, 120.2440),
    'ä»å¾·å€': (22.9385, 120.2545), 'æ­¸ä»å€': (22.9049, 120.3027),
    'å–„åŒ–å€': (23.1310, 120.2978), 'æ–°åŒ–å€': (23.0383, 120.3119),
    'å®‰å—å€': (23.0468, 120.1853), 'å®‰å¹³å€': (22.9927, 120.1659),
    'æ±å€': (22.9798, 120.2252),   'åŒ—å€': (23.0030, 120.2080),
    'å—å€': (22.9600, 120.1980),   'ä¸­è¥¿å€': (22.9920, 120.2000),
    'å½°åŒ–å¸‚': (24.0827, 120.5417), 'å“¡æ—å¸‚': (23.9590, 120.5740),
    'é¹¿æ¸¯é®': (24.0585, 120.4325), 'èŠ±å£‡é„‰': (24.0937, 120.5146),
    'å—æŠ•å¸‚': (23.9120, 120.6672), 'è‰å±¯é®': (23.9740, 120.6800),
    'åŸ”é‡Œé®': (23.9610, 120.9660), 'ç«¹å±±é®': (23.7599, 120.6861),
    'é¹½åŸ•å€': (22.6230, 120.2836), 'å‰é‡‘å€': (22.6266, 120.2952),
    'æ–°èˆˆå€': (22.6296, 120.3090), 'æ——æ´¥å€': (22.5898, 120.2653),
    'æ—åœ’å€': (22.5100, 120.3927), 'å¤§æ¨¹å€': (22.7240, 120.4300),
    'æ–°ç‡Ÿå€': (23.3032, 120.3031), 'éº»è±†å€': (23.1793, 120.2411),
    'ä½³é‡Œå€': (23.1602, 120.1808), 'åé‡Œå€': (24.3185, 120.7436),
    'è±åŸå€': (24.2543, 120.7182), 'æ±å‹¢å€': (24.2569, 120.7920),
    'æ——å±±å€': (22.8861, 120.4839), 'ç¾æ¿ƒå€': (22.8982, 120.5421),
}


def get_district_coordinates(district):
    if district in DISTRICT_COORDINATES:
        return DISTRICT_COORDINATES[district]
    for key in DISTRICT_COORDINATES:
        if district in key or key in district:
            return DISTRICT_COORDINATES[key]
    return (24.5, 121.0)


# ============================================================
# Geocodingï¼ˆNominatim + æª”æ¡ˆå¿«å–ï¼‰
# ============================================================
def load_geocode_cache():
    global _geocode_cache
    if os.path.exists(GEOCODE_CACHE_PATH):
        try:
            with open(GEOCODE_CACHE_PATH, 'r', encoding='utf-8') as f:
                _geocode_cache = json.load(f)
            print(f"ğŸ“ å·²è¼‰å…¥ {len(_geocode_cache)} ç­†åº§æ¨™å¿«å–")
        except Exception:
            _geocode_cache = {}


def save_geocode_cache():
    with _geocode_lock:
        try:
            with open(GEOCODE_CACHE_PATH, 'w', encoding='utf-8') as f:
                json.dump(_geocode_cache, f, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  å¿«å–å„²å­˜å¤±æ•—: {e}")


def clean_address_for_geocoding(address):
    addr = str(address)
    addr = re.sub(r'\d+æ¨“.*$', '', addr)
    addr = re.sub(r'[A-Za-z]\d*æ£Ÿ.*$', '', addr)
    addr = re.sub(r'åº—[A-Z].*$', '', addr)
    addr = re.sub(r'(?:å’Œ|èˆ‡|åŠ).+?(?:äº¤å‰|è·¯å£).*$', '', addr)
    if not addr.startswith(('å°ç£', 'è‡ºç£')):
        addr = 'å°ç£ ' + addr
    return addr.strip()


def nominatim_geocode(address):
    clean_addr = clean_address_for_geocoding(address)
    try:
        url = (
            'https://nominatim.openstreetmap.org/search'
            f'?q={quote_plus(clean_addr)}'
            '&format=json&limit=1&countrycodes=tw'
        )
        req = Request(url, headers={'User-Agent': 'LiangFuEstate/3.0'})
        with urlopen(req, timeout=8) as resp:
            data = json.loads(resp.read().decode('utf-8'))
            if data:
                return [float(data[0]['lat']), float(data[0]['lon'])]
    except Exception:
        pass
    return None


def get_coordinates(address, district):
    if address in _geocode_cache:
        c = _geocode_cache[address]
        return (c[0], c[1])
    return get_district_coordinates(district)


def background_geocoder():
    time.sleep(5)
    uncached = [
        p for p in _building_projects
        if p['representative_address'] not in _geocode_cache
    ]
    if not uncached:
        print("ğŸ“ æ‰€æœ‰å»ºæ¡ˆåº§æ¨™å·²å¿«å–")
        return
    uncached.sort(key=lambda x: x['transaction_count'], reverse=True)
    print(f"ğŸ“ èƒŒæ™¯ Geocodingï¼š{len(uncached)} ç­†å¾…è™•ç†")
    success = 0
    for i, proj in enumerate(uncached):
        addr = proj['representative_address']
        result = nominatim_geocode(addr)
        if result:
            with _geocode_lock:
                _geocode_cache[addr] = result
            success += 1
        time.sleep(1.1)
        if (i + 1) % 50 == 0:
            save_geocode_cache()
            print(f"  ğŸ“ é€²åº¦ {i+1}/{len(uncached)}ï¼ŒæˆåŠŸ {success}")
    save_geocode_cache()
    print(f"ğŸ“ Geocoding å®Œæˆï¼š{success}/{len(uncached)}")


# ============================================================
# åˆå§‹åŒ–
# ============================================================
def init_database():
    global _db
    csv_mtime = os.path.getmtime(CSV_PATH) if os.path.exists(CSV_PATH) else 0
    db_exists = os.path.exists(DB_PATH)
    db_mtime = os.path.getmtime(DB_PATH) if db_exists else 0
    need_rebuild = not db_exists or csv_mtime > db_mtime

    if need_rebuild:
        print("ğŸ“¦ å»ºç«‹ DuckDB è³‡æ–™åº«ï¼ˆé¦–æ¬¡éœ€ç´„ 30 ç§’ï¼‰â€¦")
        if db_exists:
            os.remove(DB_PATH)
        con = duckdb.connect(DB_PATH)
        con.execute(f"""
            CREATE TABLE transactions AS
            SELECT * FROM read_csv_auto('{CSV_PATH}')
            WHERE "é„‰é®å¸‚å€" IS NOT NULL
              AND "é„‰é®å¸‚å€" != 'The villages and towns urban district'
              AND "é„‰é®å¸‚å€" != ''
        """)
        con.execute('CREATE INDEX idx_district ON transactions("é„‰é®å¸‚å€")')
        row_count = con.execute('SELECT COUNT(*) FROM transactions').fetchone()[0]
        con.close()
        print(f"âœ… DuckDB å»ºç«‹å®Œæˆï¼š{row_count:,} ç­†äº¤æ˜“")
    else:
        print("âœ… ä½¿ç”¨æ—¢æœ‰ DuckDB è³‡æ–™åº«")

    _db = duckdb.connect(DB_PATH, read_only=True)


def get_db():
    global _db
    if _db is None:
        _db = duckdb.connect(DB_PATH, read_only=True)
    return _db


def init_data():
    global _building_projects, _building_index, _data_ready

    print("ğŸ—ï¸  è¼‰å…¥å»ºæ¡ˆè³‡æ–™åº«â€¦")
    init_database()
    load_geocode_cache()

    try:
        con = duckdb.connect()
        df = con.execute(
            f"SELECT * FROM read_csv_auto('{BUILDING_CSV_PATH}')"
        ).fetchdf()
        con.close()

        projects = []
        for _, row in df.iterrows():
            name = str(row.get('å»ºæ¡ˆåç¨±', '')).strip()
            if not name or name == 'å»ºæ¡ˆåç¨±':
                continue
            pid = hashlib.md5(name.encode()).hexdigest()[:12]
            district = str(row.get('é„‰é®å¸‚å€', '')).strip()
            addr_raw = str(row.get('ä»£è¡¨åœ°å€', '')).strip()
            addr = fullwidth_to_halfwidth(addr_raw)
            lat, lng = get_coordinates(addr_raw, district)

            avg_price = 0
            try:
                avg_price = float(row.get('å¹³å‡æˆäº¤åƒ¹å…ƒ', 0) or 0)
            except (ValueError, TypeError):
                pass

            avg_area = 0
            try:
                avg_area = float(row.get('å¹³å‡é¢ç©å¹³æ–¹å…¬å°º', 0) or 0)
            except (ValueError, TypeError):
                pass

            tx_count = 0
            try:
                tx_count = int(row.get('äº¤æ˜“ç­†æ•¸', 0) or 0)
            except (ValueError, TypeError):
                pass

            max_floors_raw = str(row.get('æœ€é«˜æ¨“å±¤', ''))
            max_floors = _fmt_total_floors(max_floors_raw)

            proj = {
                'id': pid,
                'name': name,
                'address': addr,
                'district': district,
                'transaction_count': tx_count,
                'building_type': str(row.get('å»ºç‰©å‹æ…‹', '')),
                'max_floors': max_floors,
                'avg_price': avg_price,
                'avg_area_sqm': avg_area,
                'avg_ping': round(avg_area / PING_TO_SQM, 2) if avg_area else 0,
                'avg_unit_price_ping': round(avg_price / (avg_area / PING_TO_SQM), 0) if avg_area > 0 else 0,
                'address_count': int(row.get('åœ°å€æ•¸é‡', 0) or 0),
                'representative_address': addr,
                'address_patterns': extract_address_patterns(addr),
                'year_range': str(row.get('äº¤æ˜“å¹´ä»½ç¯„åœ', '')),
                'lat': lat,
                'lng': lng,
                'is_address_result': False,
            }
            projects.append(proj)
            _building_index[pid] = proj

        _building_projects = sorted(
            projects, key=lambda x: x['transaction_count'], reverse=True)
        _data_ready = True
        print(f"âœ… è¼‰å…¥ {len(_building_projects)} å€‹å»ºæ¡ˆ")
    except Exception as e:
        print(f"âŒ è¼‰å…¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        _data_ready = True


# ============================================================
# å·¥å…·
# ============================================================
def clean_nan(obj):
    if isinstance(obj, dict):
        return {k: clean_nan(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [clean_nan(v) for v in obj]
    if isinstance(obj, float) and (math.isnan(obj) or math.isinf(obj)):
        return 0
    return obj


def format_roc_date(roc_date):
    if not roc_date:
        return None
    ds = str(roc_date).strip()
    if len(ds) < 7:
        return None
    try:
        y = int(ds[:3]) + 1911
        return f"{y}/{ds[3:5]}/{ds[5:7]}"
    except Exception:
        return None


def _make_tx_record(row):
    """å¾ DuckDB row çµ„å‡ºæ ¼å¼åŒ–äº¤æ˜“è¨˜éŒ„ dict"""
    note = str(row.get('å‚™è¨»', '') or '')
    specials = detect_special_transaction(note)

    price = 0
    try:
        price = float(row.get('ç¸½åƒ¹å…ƒ', 0) or 0)
    except (ValueError, TypeError):
        pass

    unit_price_sqm = 0
    try:
        unit_price_sqm = float(row.get('å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º', 0) or 0)
    except (ValueError, TypeError):
        pass

    area_sqm = 0
    try:
        area_sqm = float(row.get('å»ºç‰©ç§»è½‰ç¸½é¢ç©å¹³æ–¹å…¬å°º', 0) or 0)
    except (ValueError, TypeError):
        pass

    main_area = 0
    try:
        main_area = float(row.get('ä¸»å»ºç‰©é¢ç©', 0) or 0)
    except (ValueError, TypeError):
        pass

    ping = area_sqm / PING_TO_SQM if area_sqm else 0
    upping = unit_price_sqm * PING_TO_SQM if unit_price_sqm else 0
    ratio = ((area_sqm - main_area) / area_sqm * 100) \
        if area_sqm > 0 and main_area > 0 else None

    parking_price = 0
    try:
        parking_price = float(row.get('è»Šä½ç¸½åƒ¹å…ƒ', 0) or 0)
    except (ValueError, TypeError):
        pass
    parking_area = 0
    try:
        parking_area = float(row.get('è»Šä½ç§»è½‰ç¸½é¢ç©(å¹³æ–¹å…¬å°º)', 0) or 0)
    except (ValueError, TypeError):
        pass

    floor_raw = str(row.get('ç§»è½‰å±¤æ¬¡', '') or '')
    total_floors_raw = str(row.get('ç¸½æ¨“å±¤æ•¸', '') or '')

    return {
        'date': format_roc_date(row.get('äº¤æ˜“å¹´æœˆæ—¥')),
        'date_raw': str(row.get('äº¤æ˜“å¹´æœˆæ—¥', '')),
        'address': fullwidth_to_halfwidth(str(row.get('åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ', ''))),
        'floor': format_floor(floor_raw, total_floors_raw),
        'total_floors': _fmt_total_floors(total_floors_raw),
        'rooms': str(row.get('å»ºç‰©ç¾æ³æ ¼å±€-æˆ¿', '') or ''),
        'halls': str(row.get('å»ºç‰©ç¾æ³æ ¼å±€-å»³', '') or ''),
        'baths': str(row.get('å»ºç‰©ç¾æ³æ ¼å±€-è¡›', '') or ''),
        'building_type': str(row.get('å»ºç‰©å‹æ…‹', '')),
        'price': price,
        'unit_price_ping': round(upping, 0),
        'area_ping': round(ping, 2),
        'ratio': round(ratio, 1) if ratio is not None else None,
        'parking_type': str(row.get('è»Šä½é¡åˆ¥', '')),
        'parking_price': parking_price,
        'parking_area': parking_area,
        'note': note,
        'special': specials,
        'has_elevator': str(row.get('é›»æ¢¯', '')),
        'has_management': str(row.get('æœ‰ç„¡ç®¡ç†çµ„ç¹”', '')),
        'main_use': str(row.get('ä¸»è¦ç”¨é€”', '')),
        'main_material': str(row.get('ä¸»è¦å»ºæ', '')),
        'build_date': str(row.get('å»ºç¯‰å®Œæˆå¹´æœˆ', '')),
        'transaction_target': str(row.get('äº¤æ˜“æ¨™çš„', '')),
    }


# ============================================================
# DuckDB åœ°å€æœå°‹
# ============================================================
def search_addresses_in_db(keyword, limit=60):
    """åœ¨ DuckDB æœå°‹å«é—œéµå­—çš„åœ°å€ï¼Œèšåˆå¾Œå›å‚³è™›æ“¬å»ºæ¡ˆåˆ—è¡¨"""
    kw = fullwidth_to_halfwidth(keyword)  # è½‰æˆåŠå½¢
    kw_fullwidth = halfwidth_to_fullwidth(kw)  # ç”Ÿæˆå…¨å½¢ç‰ˆæœ¬
    try:
        con = get_db()
        
        # ä½¿ç”¨ OR ç›´æ¥åˆä½µå…©å€‹æ¨¡å¼
        df = con.execute("""
            SELECT
                "é„‰é®å¸‚å€" AS district,
                "åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ" AS address,
                COUNT(*) AS tx_count,
                AVG(TRY_CAST("ç¸½åƒ¹å…ƒ" AS DOUBLE)) AS avg_price,
                AVG(TRY_CAST("å»ºç‰©ç§»è½‰ç¸½é¢ç©å¹³æ–¹å…¬å°º" AS DOUBLE)) AS avg_area,
                AVG(TRY_CAST("å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º" AS DOUBLE)) AS avg_unit_sqm,
                MAX("ç¸½æ¨“å±¤æ•¸") AS max_floors,
                MAX("å»ºç‰©å‹æ…‹") AS building_type
            FROM transactions
            WHERE ("åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ" LIKE ? OR "åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ" LIKE ?)
              AND TRY_CAST("ç¸½åƒ¹å…ƒ" AS DOUBLE) > 0
            GROUP BY "é„‰é®å¸‚å€", "åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ"
            ORDER BY tx_count DESC, "é„‰é®å¸‚å€", "åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ"
            LIMIT ?
        """, [f'%{kw}%', f'%{kw_fullwidth}%', limit * 2]).fetchdf()

        results = []
        for _, row in df.iterrows():
            addr_raw = str(row['address'])
            addr = fullwidth_to_halfwidth(addr_raw)
            district = str(row['district'])
            pid = 'addr_' + hashlib.md5(
                f"{district}_{addr_raw}".encode()
            ).hexdigest()[:12]

            avg_price = float(row['avg_price'] or 0)
            avg_area = float(row['avg_area'] or 0)
            avg_unit_sqm = float(row['avg_unit_sqm'] or 0)
            ping = avg_area / PING_TO_SQM if avg_area else 0
            upping = avg_unit_sqm * PING_TO_SQM if avg_unit_sqm else 0

            proj = {
                'id': pid,
                'name': addr,
                'address': addr,
                'address_raw': addr_raw,
                'representative_address': addr,
                'district': district,
                'transaction_count': int(row['tx_count']),
                'building_type': str(row['building_type'] or ''),
                'max_floors': _fmt_total_floors(str(row['max_floors'] or '')),
                'avg_price': avg_price,
                'avg_area': ping,
                'avg_area_sqm': avg_area,
                'unit_price_ping': upping,
                'address_count': 1,
                'year_range': '',
                'lat': get_district_coordinates(district)[0],
                'lng': get_district_coordinates(district)[1],
                'is_address_result': True,
            }
            _address_index[pid] = {
                'address_raw': addr_raw,
                'address': addr,
                'district': district,
            }
            results.append(proj)
        return results
    except Exception as e:
        print(f"search_addresses_in_db error: {e}")
        import traceback
        traceback.print_exc()
        return []


# ============================================================
# Flask è·¯ç”±
# ============================================================

@app.route('/')
def index():
    with open('liangfu_map.html', 'r', encoding='utf-8') as f:
        return f.read()



@app.route('/api/projects', methods=['GET'])
def api_projects():
    """å»ºæ¡ˆåˆ—è¡¨ï¼ˆå«åœ°å€æœå°‹ fallbackï¼‰"""
    keyword = request.args.get('keyword', '').strip()
    district = request.args.get('district', '').strip()
    building_type = request.args.get('building_type', '').strip()
    min_price = request.args.get('min_price', type=float)
    max_price = request.args.get('max_price', type=float)
    min_ping = request.args.get('min_ping', type=float)
    max_ping = request.args.get('max_ping', type=float)
    sort_by = request.args.get('sort_by', 'transaction_count')
    sort_order = request.args.get('sort_order', 'desc')
    page = request.args.get('page', 1, type=int)
    limit = request.args.get('limit', 200, type=int)

    results = list(_building_projects)

    if keyword:
        kw = fullwidth_to_halfwidth(keyword).lower()
        results = [
            p for p in results
            if kw in p['name'].lower()
            or kw in p['district'].lower()
            or kw in p['representative_address'].lower()
            or kw in p['building_type'].lower()
        ]
    if district:
        results = [p for p in results if district in p['district']]
    if building_type:
        results = [p for p in results if building_type in p['building_type']]
    if min_price is not None:
        results = [p for p in results if p['avg_price'] >= min_price]
    if max_price is not None:
        results = [p for p in results if p['avg_price'] <= max_price]
    if min_ping is not None:
        results = [p for p in results if p['avg_area_sqm'] >= min_ping * PING_TO_SQM]
    if max_ping is not None:
        results = [p for p in results if p['avg_area_sqm'] <= max_ping * PING_TO_SQM]

    # --- é—œéµå­— >= 2 å­—ï¼Œè£œå…… DuckDB åœ°å€æœå°‹ ---
    addr_results = []
    if keyword and len(keyword) >= 2:
        addr_results = search_addresses_in_db(keyword, limit=60)
        existing = {p['representative_address'] for p in results}
        addr_results = [a for a in addr_results if a['representative_address'] not in existing]
        if district:
            addr_results = [a for a in addr_results if district in a['district']]
        if building_type:
            addr_results = [a for a in addr_results if building_type in a['building_type']]

    merged = results + addr_results

    sort_keys = {
        'transaction_count': 'transaction_count',
        'price': 'avg_price',
        'area': 'avg_area_sqm',
        'unit_price': 'avg_unit_price_ping',
        'name': 'name',
    }
    sk = sort_keys.get(sort_by, 'transaction_count')
    rev = sort_order != 'asc'
    try:
        merged.sort(key=lambda x: x.get(sk, 0) or 0, reverse=rev)
    except Exception:
        pass

    total = len(merged)
    start = (page - 1) * limit
    page_results = merged[start:start + limit]

    for p in page_results:
        addr = p.get('representative_address', '')
        if addr in _geocode_cache:
            c = _geocode_cache[addr]
            p['lat'], p['lng'] = c[0], c[1]

    return jsonify(clean_nan({
        'success': True,
        'total': total,
        'page': page,
        'limit': limit,
        'building_count': len(results),
        'address_count': len(addr_results),
        'projects': page_results,
    }))


@app.route('/api/project/<project_id>', methods=['GET'])
def api_project_detail(project_id):
    """å»ºæ¡ˆè©³æƒ…ï¼ˆæ”¯æ´å»ºæ¡ˆè¡¨ & åœ°å€æœå°‹çµæœï¼‰"""

    if project_id.startswith('addr_'):
        # â”€â”€ åœ°å€æœå°‹çµæœ â”€â”€
        info = _address_index.get(project_id)
        if not info:
            return jsonify({'success': False, 'error': 'æ‰¾ä¸åˆ°æ­¤åœ°å€ï¼ˆè«‹é‡æ–°æœå°‹ï¼‰'}), 404
        district = info['district']
        addr_raw = info['address_raw']
        addr = info['address']
        proj = {
            'id': project_id,
            'name': addr,
            'district': district,
            'representative_address': addr,
            'building_type': '',
            'max_floors': '',
            'is_address_result': True,
        }
        try:
            con = get_db()
            df = con.execute("""
                SELECT * FROM transactions
                WHERE "é„‰é®å¸‚å€" = ? AND "åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ" = ?
                  AND TRY_CAST("ç¸½åƒ¹å…ƒ" AS DOUBLE) > 0
                ORDER BY "äº¤æ˜“å¹´æœˆæ—¥" DESC LIMIT 500
            """, [district, addr_raw]).fetchdf()
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500
    else:
        # â”€â”€ å»ºæ¡ˆè¡¨ â”€â”€
        proj = _building_index.get(project_id)
        if not proj:
            return jsonify({'success': False, 'error': 'æ‰¾ä¸åˆ°æ­¤å»ºæ¡ˆ'}), 404
        district = proj['district']
        patterns = proj.get('address_patterns', [])

        try:
            con = get_db()
            df = None
            for pat in patterns:
                test_df = con.execute("""
                    SELECT * FROM transactions
                    WHERE "é„‰é®å¸‚å€" = ? AND "åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ" LIKE ?
                      AND TRY_CAST("ç¸½åƒ¹å…ƒ" AS DOUBLE) > 0
                    ORDER BY "äº¤æ˜“å¹´æœˆæ—¥" DESC LIMIT 500
                """, [district, f'%{pat}%']).fetchdf()
                if len(test_df) >= 3:
                    df = test_df
                    break
            if df is None and patterns:
                df = con.execute("""
                    SELECT * FROM transactions
                    WHERE "é„‰é®å¸‚å€" = ? AND "åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ" LIKE ?
                      AND TRY_CAST("ç¸½åƒ¹å…ƒ" AS DOUBLE) > 0
                    ORDER BY "äº¤æ˜“å¹´æœˆæ—¥" DESC LIMIT 500
                """, [district, f'%{patterns[-1]}%']).fetchdf()
            if df is None:
                df = con.execute("""
                    SELECT * FROM transactions
                    WHERE "é„‰é®å¸‚å€" = ?
                      AND TRY_CAST("ç¸½åƒ¹å…ƒ" AS DOUBLE) > 0
                    ORDER BY "äº¤æ˜“å¹´æœˆæ—¥" DESC LIMIT 200
                """, [district]).fetchdf()
        except Exception as e:
            import traceback
            traceback.print_exc()
            return jsonify({'success': False, 'error': str(e)}), 500

    # â”€â”€ çµ„åˆäº¤æ˜“ç´€éŒ„ â”€â”€
    transactions = []
    special_count = 0
    total_price = total_unit = total_area = 0
    count = 0

    for _, row in df.iterrows():
        tx = _make_tx_record(row)
        if tx['special']:
            special_count += 1
        total_price += tx['price']
        total_unit += tx['unit_price_ping']
        total_area += tx['area_ping']
        count += 1
        transactions.append(tx)

    summary = {
        'total_transactions': count,
        'special_count': special_count,
        'avg_price': round(total_price / count, 0) if count else 0,
        'avg_unit_price': round(total_unit / count, 0) if count else 0,
        'avg_area': round(total_area / count, 2) if count else 0,
    }

    return jsonify(clean_nan({
        'success': True,
        'project': proj,
        'summary': summary,
        'transactions': transactions,
    }))


@app.route('/api/stats', methods=['GET'])
def api_stats():
    total_projects = len(_building_projects)
    total_tx = sum(p['transaction_count'] for p in _building_projects)
    districts = defaultdict(int)
    for p in _building_projects:
        districts[p['district']] += p['transaction_count']
    top_districts = sorted(districts.items(), key=lambda x: -x[1])[:20]
    return jsonify({
        'success': True,
        'total_projects': total_projects,
        'total_transactions': total_tx,
        'top_districts': [{'district': d, 'count': c} for d, c in top_districts],
    })


@app.route('/api/districts', methods=['GET'])
def api_districts():
    districts = sorted(set(p['district'] for p in _building_projects if p['district']))
    try:
        con = get_db()
        db_d = con.execute(
            'SELECT DISTINCT "é„‰é®å¸‚å€" FROM transactions '
            'WHERE "é„‰é®å¸‚å€" IS NOT NULL ORDER BY 1'
        ).fetchdf()['é„‰é®å¸‚å€'].tolist()
        return jsonify({'success': True, 'districts': sorted(set(districts + db_d))})
    except Exception:
        return jsonify({'success': True, 'districts': districts})


# ============================================================
if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ¢ è‰¯å¯Œå±…åœ°ç”¢ v3.0")
    print("=" * 60)
    print(f"ğŸ“ äº¤æ˜“ CSV: {CSV_PATH}")
    print(f"ğŸ“ å»ºæ¡ˆ CSV: {BUILDING_CSV_PATH}")
    print("=" * 60)

    init_data()

    t = threading.Thread(target=background_geocoder, daemon=True)
    t.start()

    print(f"ğŸ–¥ï¸  http://localhost:5000")
    app.run(debug=False, host='0.0.0.0', port=5000)
