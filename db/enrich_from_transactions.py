#!/usr/bin/env python3
"""
enrich_from_transactions.py  v2
================================
å¾ transactions.db (591 API) è£œå…… land_data.db æ‰€æœ‰ç¼ºå¤±æ¬„ä½ã€‚

åŒ¹é…ç­–ç•¥ï¼ˆä¾å„ªå…ˆé †åºï¼‰ï¼š
  1. æ­£è¦åŒ–å…¨å€åŒ¹é…ï¼ˆå»åŸå¸‚å‰ç¶´ã€å…¨åŠå½¢çµ±ä¸€ï¼‰
  2. æ—¥æœŸ + ç¸½åƒ¹åŒ¹é…ï¼ˆè§£æ±ºåœ°å€æ ¼å¼ä¸åŒçš„å•é¡Œï¼‰
  3. å»æ¨“å±¤åŸºç¤åœ°å€åŒ¹é…ï¼ˆåŒæ£Ÿä¸åŒæ¨“å…±äº« lat/lng/communityï¼‰

è£œå……æ¬„ä½ï¼ˆåªè£œç©ºç™½ï¼Œä¸è¦†è“‹ç¾æœ‰ï¼‰ï¼š
  lat, lng, community_name, building_type, main_use,
  has_management, rooms, halls, bathrooms, building_area,
  unit_price, transaction_type, floor_level, total_floors, note
"""

import sqlite3
import re
import json
import os
import time

DB_LAND  = os.path.join(os.path.dirname(__file__), 'land_data.db')
DB_TRANS = os.path.join(os.path.dirname(__file__), 'transactions.db')

# â”€â”€â”€ åœ°å€æ­£è¦åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CHINESE_FLOOR = {
    'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9,
    'å': 10, 'åä¸€': 11, 'åäºŒ': 12, 'åä¸‰': 13, 'åå››': 14, 'åäº”': 15,
    'åå…­': 16, 'åä¸ƒ': 17, 'åå…«': 18, 'åä¹': 19, 'äºŒå': 20,
    'äºŒåä¸€': 21, 'äºŒåäºŒ': 22, 'äºŒåä¸‰': 23, 'äºŒåå››': 24, 'äºŒåäº”': 25,
    'äºŒåå…­': 26, 'äºŒåä¸ƒ': 27, 'äºŒåå…«': 28, 'äºŒåä¹': 29, 'ä¸‰å': 30,
    'åœ°ä¸‹ä¸€': -1, 'åœ°ä¸‹äºŒ': -2, 'åœ°ä¸‹ä¸‰': -3,
}

def norm_addr(addr):
    """å…¨å½¢â†’åŠå½¢ã€è‡ºâ†’å°ã€ä¸­æ–‡æ¨“å±¤â†’æ•¸å­—"""
    result = []
    for ch in (addr or ''):
        code = ord(ch)
        if 0xFF01 <= code <= 0xFF5E:
            result.append(chr(code - 0xFEE0))
        else:
            result.append(ch)
    addr = ''.join(result).replace('è‡º', 'å°').replace(' ', '')
    addr = re.sub(
        r'(åœ°ä¸‹[ä¸€äºŒä¸‰]|äºŒå[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹]|ä¸‰å|äºŒå|å[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹]|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])(æ¨“|å±¤)',
        lambda m: str(CHINESE_FLOOR.get(m.group(1), m.group(1))) + m.group(2),
        addr
    )
    return addr

CITY_PREFIXES = [
    'å°åŒ—å¸‚', 'æ–°åŒ—å¸‚', 'æ¡ƒåœ’å¸‚', 'å°ä¸­å¸‚', 'å°å—å¸‚', 'é«˜é›„å¸‚',
    'åŸºéš†å¸‚', 'æ–°ç«¹å¸‚', 'å˜‰ç¾©å¸‚', 'æ–°ç«¹ç¸£', 'è‹—æ —ç¸£', 'å½°åŒ–ç¸£',
    'å—æŠ•ç¸£', 'é›²æ—ç¸£', 'å˜‰ç¾©ç¸£', 'å±æ±ç¸£', 'å®œè˜­ç¸£', 'èŠ±è“®ç¸£',
    'å°æ±ç¸£', 'æ¾æ¹–ç¸£', 'é‡‘é–€ç¸£', 'é€£æ±Ÿç¸£', 'æ¡ƒåœ’ç¸£', 'å°åŒ—ç¸£',
    'å°ä¸­ç¸£', 'å°å—ç¸£', 'é«˜é›„ç¸£',
]

def strip_city(addr):
    for prefix in CITY_PREFIXES:
        if addr.startswith(prefix):
            return addr[len(prefix):]
    return addr

def strip_floor(addr):
    """å»é™¤å°¾ç«¯æ¨“å±¤è³‡è¨Šï¼Œå–å¾—å»ºç‰©åŸºç¤åœ°å€"""
    addr = re.sub(r'(-\d+|åœ°ä¸‹\d+|\d+)æ¨“[ä¹‹\d]*$', '', addr)
    addr = addr.rstrip('ä¹‹å·è™Ÿ ')
    return addr

def parse_price(val):
    if not val:
        return None
    try:
        return int(str(val).replace(',', '').replace(' ', ''))
    except Exception:
        return None

def normalize_date(date_str):
    """101/01/05 â†’ 1010105, 1010105 â†’ 1010105"""
    if not date_str:
        return ''
    return date_str.replace('/', '')

def parse_floor_info(floor_str):
    """'ä¹å±¤/åäº”å±¤' â†’ (floor_level, total_floors)"""
    if not floor_str:
        return '', ''
    parts = floor_str.split('/')
    if len(parts) == 2:
        return parts[0].strip(), parts[1].strip()
    return floor_str.strip(), ''


# â”€â”€â”€ è³‡æ–™çµæ§‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ENRICH_FIELDS = [
    'lat', 'lng', 'community', 'building_type', 'main_use',
    'has_management', 'rooms', 'halls', 'bathrooms', 'building_area',
    'unit_price', 'transaction_type', 'floor_level', 'total_floors', 'note',
]

def make_edata(lat=None, lng=None, community='', building_type='',
               main_use='', has_management='', rooms=None, halls=None,
               bathrooms=None, building_area=None, unit_price=None,
               transaction_type='', floor_level='', total_floors='', note=''):
    return {
        'lat': lat, 'lng': lng, 'community': community,
        'building_type': building_type, 'main_use': main_use,
        'has_management': has_management, 'rooms': rooms, 'halls': halls,
        'bathrooms': bathrooms, 'building_area': building_area,
        'unit_price': unit_price, 'transaction_type': transaction_type,
        'floor_level': floor_level, 'total_floors': total_floors,
        'note': note,
    }

def richness(d):
    score = 0
    if d.get('lat') and d['lat'] != 0: score += 3
    if d.get('community'): score += 3
    if d.get('rooms') is not None: score += 1
    if d.get('halls') is not None: score += 1
    if d.get('bathrooms') is not None: score += 1
    if d.get('building_area'): score += 1
    if d.get('building_type'): score += 1
    if d.get('main_use'): score += 1
    if d.get('has_management'): score += 1
    if d.get('transaction_type'): score += 1
    return score

def merge_into(target, source):
    """å¾ source è£œå…… target ç¼ºå¤±çš„æ¬„ä½"""
    for f in ENRICH_FIELDS:
        tv = target.get(f)
        if tv is None or tv == '' or tv == 0:
            sv = source.get(f)
            if sv is not None and sv != '' and sv != 0:
                target[f] = sv


def parse_transaction_row(row):
    """å¾ transactions.db ä¸€åˆ—è§£æå‡º edata dict + keys"""
    addr_raw, lat, lon, community, build_type, date_str, floor_col, area, tp, up, rj_text = row

    lat = lat if (lat and lat != 0) else None
    lng = lon if (lon and lon != 0) else None
    community = (community or '').strip()

    j = {}
    if rj_text:
        try:
            j = json.loads(rj_text)
        except Exception:
            pass

    floor_json = j.get('f', '') or floor_col or ''
    floor_level, total_floors = parse_floor_info(floor_json)

    rooms = halls = bathrooms = None
    try:
        rooms = int(j['j']) if j.get('j', '') != '' else None
    except Exception:
        pass
    try:
        halls = int(j['k']) if j.get('k', '') != '' else None
    except Exception:
        pass
    try:
        bathrooms = int(j['l']) if j.get('l', '') != '' else None
    except Exception:
        pass

    has_management = j.get('m', '') or ''
    main_use = j.get('pu', '') or j.get('AA11', '') or ''
    transaction_type = j.get('t', '') or ''
    note = j.get('note', '') or ''
    building_type = build_type or j.get('b', '') or ''

    building_area = None
    try:
        v = area or j.get('s', '')
        if v:
            building_area = float(str(v).replace(',', ''))
    except Exception:
        pass

    unit_price = None
    try:
        v = j.get('cp', '')
        if v:
            unit_price = float(str(v).replace(',', ''))
    except Exception:
        pass

    total_price = parse_price(j.get('tp'))

    clean = addr_raw.split('#', 1)[1] if (addr_raw and '#' in addr_raw) else (addr_raw or '')
    norm = strip_city(norm_addr(clean))
    base = strip_floor(norm)
    date_norm = normalize_date(date_str)

    edata = make_edata(
        lat=lat, lng=lng, community=community, building_type=building_type,
        main_use=main_use, has_management=has_management,
        rooms=rooms, halls=halls, bathrooms=bathrooms,
        building_area=building_area, unit_price=unit_price,
        transaction_type=transaction_type, floor_level=floor_level,
        total_floors=total_floors, note=note,
    )
    return edata, norm, base, date_norm, total_price


# â”€â”€â”€ ä¸»é‚è¼¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_trans_maps():
    """å¾ transactions.db å»ºç«‹ä¸‰ç¨®æ˜ å°„è¡¨"""
    print("Step 1: è®€å– transactions.db å»ºç«‹æ˜ å°„è¡¨...", flush=True)
    conn = sqlite3.connect(DB_TRANS)
    conn.text_factory = lambda b: b.decode('utf-8', errors='replace')
    cur = conn.cursor()
    cur.execute("""
        SELECT address, lat, lon, community, build_type, date_str, floor, area,
               total_price, unit_price, raw_json
        FROM transactions
        WHERE address IS NOT NULL AND address != '' AND address != '#'
    """)

    full_map = {}       # norm å®Œæ•´åœ°å€ â†’ edata
    date_price_map = {} # (date, total_price) â†’ edata
    base_map = {}       # norm åŸºç¤åœ°å€ï¼ˆå»æ¨“å±¤ï¼‰â†’ edata

    count = 0
    for row in cur:
        try:
            edata, norm, base, date_norm, total_price = parse_transaction_row(row)
        except Exception:
            continue

        if not norm:
            continue

        # 1. å…¨å€æ˜ å°„
        if norm not in full_map:
            full_map[norm] = edata
        elif richness(edata) > richness(full_map[norm]):
            merge_into(edata, full_map[norm])
            full_map[norm] = edata
        else:
            merge_into(full_map[norm], edata)

        # 2. æ—¥æœŸ+ç¸½åƒ¹æ˜ å°„
        if date_norm and total_price and total_price > 0:
            key = (date_norm, total_price)
            if key not in date_price_map:
                date_price_map[key] = edata
            elif richness(edata) > richness(date_price_map[key]):
                merge_into(edata, date_price_map[key])
                date_price_map[key] = edata
            else:
                merge_into(date_price_map[key], edata)

        # 3. åŸºç¤åœ°å€æ˜ å°„ï¼ˆå»æ¨“å±¤ï¼‰
        if base and base != norm:
            if base not in base_map:
                base_map[base] = edata
            elif richness(edata) > richness(base_map[base]):
                merge_into(edata, base_map[base])
                base_map[base] = edata
            else:
                merge_into(base_map[base], edata)

        count += 1
        if count % 500_000 == 0:
            print(f"  å·²è®€å– {count:,} ç­†...", flush=True)

    conn.close()
    print(f"  å®Œæˆ: å…± {count:,} ç­†")
    print(f"  full_map:       {len(full_map):,} å€‹åœ°å€")
    print(f"  date_price_map: {len(date_price_map):,} å€‹æ—¥æœŸ+ç¸½åƒ¹")
    print(f"  base_map:       {len(base_map):,} å€‹åŸºç¤åœ°å€")
    return full_map, date_price_map, base_map


# éœ€è¦è£œå……çš„æ¬„ä½ï¼š(land_data æ¬„ä½å, edata key, ç©ºå€¼åˆ¤æ–·)
FIELD_MAP = [
    ('lat',              'lat',              lambda v: v is None or v == 0),
    ('lng',              'lng',              lambda v: v is None or v == 0),
    ('community_name',   'community',        lambda v: not v),
    ('building_type',    'building_type',    lambda v: not v),
    ('main_use',         'main_use',         lambda v: not v),
    ('has_management',   'has_management',   lambda v: not v),
    ('rooms',            'rooms',            lambda v: v is None),
    ('halls',            'halls',            lambda v: v is None),
    ('bathrooms',        'bathrooms',        lambda v: v is None),
    ('building_area',    'building_area',    lambda v: v is None or v == 0),
    ('unit_price',       'unit_price',       lambda v: v is None or v == 0),
    ('transaction_type', 'transaction_type', lambda v: not v),
    ('floor_level',      'floor_level',      lambda v: not v),
    ('total_floors',     'total_floors',     lambda v: not v),
    ('note',             'note',             lambda v: not v),
]


def enrich_land_data(full_map, date_price_map, base_map):
    """æ›´æ–° land_data.db ç¼ºå¤±æ¬„ä½"""
    print("\nStep 2: æ›´æ–° land_data.db ç¼ºå¤±æ¬„ä½...", flush=True)

    # è®€å¯«åˆ†é›¢ï¼šread_conn å”¯è®€ï¼ˆé¿å… SELECT cursor è¢« WAL checkpoint å¹²æ“¾ï¼‰
    read_conn = sqlite3.connect(f'file:{DB_LAND}?mode=ro', uri=True)
    read_conn.text_factory = lambda b: b.decode('utf-8', errors='replace')
    read_conn.execute('PRAGMA cache_size=-131072')

    write_conn = sqlite3.connect(DB_LAND)
    write_conn.text_factory = lambda b: b.decode('utf-8', errors='replace')
    write_conn.execute('PRAGMA journal_mode=WAL')
    write_conn.execute('PRAGMA synchronous=NORMAL')
    write_conn.execute('PRAGMA cache_size=-65536')
    write_conn.execute('PRAGMA wal_autocheckpoint=0')  # åœç”¨è‡ªå‹• checkpointï¼Œæ‰‹å‹•æ§åˆ¶

    cols = ', '.join(['rowid', 'id', 'address', 'transaction_date', 'total_price'] +
                     [f[0] for f in FIELD_MAP])

    # å…ˆå–ç¸½æ•¸
    cur2 = read_conn.cursor()
    cur2.execute("""
        SELECT COUNT(*) FROM land_transaction
        WHERE (serial_no NOT LIKE '591_%' OR serial_no IS NULL)
          AND address LIKE '%è™Ÿ%'
    """)
    total = cur2.fetchone()[0]
    print(f"  å€™é¸è¨˜éŒ„: {total:,}", flush=True)

    updated_full  = 0
    updated_dp    = 0
    updated_base  = 0
    not_found     = 0
    already_full  = 0
    batch         = []
    BATCH_SIZE    = 10_000
    CHUNK_SIZE    = 50_000    # rowid-based åˆ†é 
    t0            = time.time()
    global_i      = 0

    # å–å€™é¸è¨˜éŒ„çš„æœ€å¤§ rowid
    cur_max = read_conn.cursor()
    cur_max.execute("""
        SELECT MAX(rowid) FROM land_transaction
        WHERE (serial_no NOT LIKE '591_%' OR serial_no IS NULL)
          AND address LIKE '%è™Ÿ%'
    """)
    max_rowid = cur_max.fetchone()[0] or 0

    last_rowid = 0
    while last_rowid <= max_rowid:
        try:
            cur = read_conn.cursor()
            cur.execute(f"""
                SELECT {cols}
                FROM land_transaction
                WHERE rowid > {last_rowid}
                  AND (serial_no NOT LIKE '591_%' OR serial_no IS NULL)
                  AND address LIKE '%è™Ÿ%'
                ORDER BY rowid
                LIMIT {CHUNK_SIZE}
            """)
            chunk = cur.fetchall()
        except sqlite3.DatabaseError as e:
            # è·³éæ­¤æ®µæå£é é¢ï¼Œå¾€å¾Œæ¨é€²
            print(f"\n  [WARN] rowid>{last_rowid:,} è®€å–å¤±æ•— ({e})ï¼Œè·³é {CHUNK_SIZE} ç­†", flush=True)
            last_rowid += CHUNK_SIZE
            continue

        if not chunk:
            break

        # æ›´æ–° last_rowid ç‚º chunk æœ€å¾Œä¸€ç­†çš„ rowidï¼Œç¢ºä¿æ­£ç¢ºæ¨é€²
        last_rowid = chunk[-1][0]

        for row in chunk:
            global_i += 1
            row_rowid    = row[0]
            row_id       = row[1]
            address      = row[2]
            trans_date   = row[3]
            land_total_price = row[4]

            current_values = {}
            for j_idx, (db_col, _, is_empty) in enumerate(FIELD_MAP):
                current_values[db_col] = row[5 + j_idx]

            needs_enrich = any(
                is_empty(current_values[db_col])
                for db_col, _, is_empty in FIELD_MAP
            )
            if not needs_enrich:
                already_full += 1
                continue

            norm = strip_city(norm_addr(address))
            base = strip_floor(norm)
            date_norm = normalize_date(trans_date)

            # å˜—è©¦ä¸‰ç¨®åŒ¹é…
            match = None
            match_type = None

            # 1. å…¨å€åŒ¹é…
            if norm in full_map:
                match = full_map[norm].copy()
                match_type = 'full'

            # 2. æ—¥æœŸ+ç¸½åƒ¹åŒ¹é…
            if date_norm and land_total_price and land_total_price > 0:
                dp_key = (date_norm, land_total_price)
                dp_match = date_price_map.get(dp_key)
                if dp_match:
                    if match is None:
                        match = dp_match.copy()
                        match_type = 'date_price'
                    else:
                        merge_into(match, dp_match)

            # 3. åŸºç¤åœ°å€åŒ¹é…ï¼ˆå»æ¨“å±¤ï¼‰
            if base and base != norm and base in base_map:
                base_match = base_map[base]
                if match is None:
                    match = base_match.copy()
                    match_type = 'base'
                else:
                    merge_into(match, base_match)

            if match is None:
                not_found += 1
                continue

            # è¨ˆç®—éœ€è¦æ›´æ–°çš„æ¬„ä½
            updates = {}
            for db_col, edata_key, is_empty in FIELD_MAP:
                if is_empty(current_values[db_col]):
                    new_val = match.get(edata_key)
                    if new_val is not None and new_val != '' and new_val != 0:
                        updates[db_col] = new_val

            if not updates:
                not_found += 1
                continue

            batch.append((updates, row_id))
            if match_type == 'full':
                updated_full += 1
            elif match_type == 'date_price':
                updated_dp += 1
            else:
                updated_base += 1

            if len(batch) >= BATCH_SIZE:
                _flush_batch(write_conn, batch)
                batch.clear()
                total_updated = updated_full + updated_dp + updated_base
                # æ¯ 100k ç­†åšä¸€æ¬¡ WAL checkpointï¼Œé˜²æ­¢ WAL ç„¡é™è†¨è„¹
                if total_updated % 100_000 == 0:
                    write_conn.execute('PRAGMA wal_checkpoint(PASSIVE)')
                elapsed = time.time() - t0
                print(f"\r  é€²åº¦: {global_i:,}/{total:,} | æ›´æ–°: {total_updated:,} "
                      f"(å…¨å€:{updated_full:,} æ—¥æœŸåƒ¹æ ¼:{updated_dp:,} åŸºç¤:{updated_base:,}) "
                      f"({elapsed:.0f}s)",
                      end='', flush=True)

    if batch:
        _flush_batch(write_conn, batch)

    write_conn.execute('PRAGMA wal_checkpoint(FULL)')
    write_conn.commit()
    write_conn.close()
    read_conn.close()

    elapsed = time.time() - t0
    total_updated = updated_full + updated_dp + updated_base
    print(f"\n\nâœ… è£œå……å®Œæˆ")
    print(f"   å€™é¸è¨˜éŒ„:     {total:,}")
    print(f"   å·²æœ‰å®Œæ•´è³‡æ–™: {already_full:,}")
    print(f"   æˆåŠŸæ›´æ–°:     {total_updated:,}")
    print(f"     å…¨å€åŒ¹é…:     {updated_full:,}")
    print(f"     æ—¥æœŸ+ç¸½åƒ¹:    {updated_dp:,}")
    print(f"     åŸºç¤åœ°å€:     {updated_base:,}")
    print(f"   æœªæ‰¾åŒ¹é…:     {not_found:,}")
    print(f"   è€—æ™‚: {elapsed:.1f}s")


def _flush_batch(conn, batch):
    """æ‰¹æ¬¡æ›´æ–°"""
    cur = conn.cursor()
    for updates, row_id in batch:
        set_clauses = []
        values = []
        for col, val in updates.items():
            set_clauses.append(f"{col} = ?")
            values.append(val)
        values.append(row_id)
        sql = f"UPDATE land_transaction SET {', '.join(set_clauses)} WHERE id = ?"
        cur.execute(sql, values)
    conn.commit()


def verify(t0_total):
    print("\nStep 3: é©—è­‰çµæœ...", flush=True)
    conn = sqlite3.connect(DB_LAND)
    cur = conn.cursor()

    cur.execute("SELECT COUNT(*) FROM land_transaction")
    n_total = cur.fetchone()[0]

    stats = []
    for db_col, _, is_empty in FIELD_MAP:
        if db_col in ('lat', 'lng', 'building_area', 'unit_price'):
            cur.execute(f"SELECT COUNT(*) FROM land_transaction WHERE {db_col} IS NOT NULL AND {db_col} != 0")
        elif db_col in ('rooms', 'halls', 'bathrooms'):
            cur.execute(f"SELECT COUNT(*) FROM land_transaction WHERE {db_col} IS NOT NULL")
        else:
            cur.execute(f"SELECT COUNT(*) FROM land_transaction WHERE {db_col} IS NOT NULL AND {db_col} != ''")
        cnt = cur.fetchone()[0]
        pct = cnt / n_total * 100
        stats.append((db_col, cnt, pct))

    conn.close()

    print(f"\nğŸ“Š land_data.db æœ€çµ‚çµ±è¨ˆ (ç¸½ç­†æ•¸: {n_total:,})")
    print(f"{'æ¬„ä½':<20} {'æœ‰å€¼ç­†æ•¸':>12} {'è¦†è“‹ç‡':>8}")
    print(f"{'â”€'*20} {'â”€'*12} {'â”€'*8}")
    for col, cnt, pct in stats:
        print(f"{col:<20} {cnt:>12,} {pct:>7.1f}%")
    print(f"\nç¸½è€—æ™‚: {time.time()-t0_total:.1f}s")


if __name__ == '__main__':
    t0 = time.time()
    full_map, date_price_map, base_map = build_trans_maps()
    enrich_land_data(full_map, date_price_map, base_map)
    verify(t0)
