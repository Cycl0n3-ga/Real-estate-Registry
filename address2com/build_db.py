#!/usr/bin/env python3
"""
build_db.py - å¾ ALL_lvr_land_b.csv å»ºç«‹åœ°å€â†’ç¤¾å€åç¨± å°ç…§è¡¨

è¼¸å‡ºæª”æ¡ˆï¼š
  - address_community_mapping.csv: å®Œæ•´å°ç…§ (æ­£è¦åŒ–åœ°å€ã€è·¯æ®µã€ç¤¾å€ã€äº¤æ˜“ç­†æ•¸ç­‰)
  - manual_mapping.csv: æ‰‹å‹•æ–°å¢ (è‹¥ä¸å­˜åœ¨)

è³‡æ–™ä¾†æºï¼š
  1. Bè¡¨ (ALL_lvr_land_b.csv): 486K ä»¶å»ºæ¡ˆäº¤æ˜“
  2. manual_mapping.csv: ç”¨æˆ¶æ‰‹å‹•æ–°å¢çš„å°ç…§
"""

import csv
import re
from pathlib import Path
from collections import defaultdict

# ========== è·¯å¾‘è¨­å®š ==========
SCRIPT_DIR = Path(__file__).parent
LAND_DIR = SCRIPT_DIR.parent
B_TABLE = LAND_DIR / "db" / "ALL_lvr_land_b.csv"
OUTPUT_CSV = SCRIPT_DIR.parent / "db" / "address_community_mapping.csv"
MANUAL_CSV = SCRIPT_DIR.parent / "db" / "manual_mapping.csv"

# ========== å…¨å½¢â†’åŠå½¢ ==========
FULLWIDTH_DIGITS = "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™"
HALFWIDTH_DIGITS = "0123456789"
FW_TO_HW = str.maketrans(FULLWIDTH_DIGITS, HALFWIDTH_DIGITS)


def fullwidth_to_halfwidth(s: str) -> str:
    return s.translate(FW_TO_HW)


# ========== ç¸£å¸‚åˆ—è¡¨ ==========
CITIES = [
    "è‡ºåŒ—å¸‚", "å°åŒ—å¸‚", "æ–°åŒ—å¸‚", "æ¡ƒåœ’å¸‚", "æ¡ƒåœ’ç¸£",
    "è‡ºä¸­å¸‚", "å°ä¸­å¸‚", "è‡ºå—å¸‚", "å°å—å¸‚", "é«˜é›„å¸‚",
    "åŸºéš†å¸‚", "æ–°ç«¹å¸‚", "æ–°ç«¹ç¸£", "è‹—æ —ç¸£", "å½°åŒ–ç¸£",
    "å—æŠ•ç¸£", "é›²æ—ç¸£", "å˜‰ç¾©å¸‚", "å˜‰ç¾©ç¸£", "å±æ±ç¸£",
    "å®œè˜­ç¸£", "èŠ±è“®ç¸£", "è‡ºæ±ç¸£", "å°æ±ç¸£", "æ¾æ¹–ç¸£",
    "é‡‘é–€ç¸£", "é€£æ±Ÿç¸£",
]

def extract_city_district(addr: str) -> tuple:
    """å¾åŸå§‹åœ°å€æå– (ç¸£å¸‚, å€)"""
    s = str(addr).strip()
    
    cities = [
        "è‡ºåŒ—å¸‚", "å°åŒ—å¸‚", "æ–°åŒ—å¸‚", "æ¡ƒåœ’å¸‚", "æ¡ƒåœ’ç¸£",
        "è‡ºä¸­å¸‚", "å°ä¸­å¸‚", "è‡ºå—å¸‚", "å°å—å¸‚", "é«˜é›„å¸‚",
        "åŸºéš†å¸‚", "æ–°ç«¹å¸‚", "æ–°ç«¹ç¸£", "è‹—æ —ç¸£", "å½°åŒ–ç¸£",
        "å—æŠ•ç¸£", "é›²æ—ç¸£", "å˜‰ç¾©å¸‚", "å˜‰ç¾©ç¸£", "å±æ±ç¸£",
        "å®œè˜­ç¸£", "èŠ±è“®ç¸£", "è‡ºæ±ç¸£", "å°æ±ç¸£", "æ¾æ¹–ç¸£",
        "é‡‘é–€ç¸£", "é€£æ±Ÿç¸£",
    ]
    
    city = ""
    for c in cities:
        if s.startswith(c):
            city = c
            s = s[len(c):]
            break
    
    # æå–å€
    m = re.match(r"([\u4e00-\u9fff]{1,3}[å€é®é„‰å¸‚])", s)
    district = m.group(1) if m else ""
    
    # æ­£è¦åŒ–ç¸£å¸‚ (å° â†’ è‡º)
    city = city.replace("å°åŒ—å¸‚", "è‡ºåŒ—å¸‚").replace("å°ä¸­å¸‚", "è‡ºä¸­å¸‚").replace("å°å—å¸‚", "è‡ºå—å¸‚").replace("å°æ±ç¸£", "è‡ºæ±ç¸£")
    
    return city, district


def normalize_address(addr: str) -> str:
    """
    æ­£è¦åŒ–åœ°å€ï¼šå»é™¤ç¸£å¸‚/å€/é‡Œé„°/æ¨“å±¤/æ£Ÿè™Ÿï¼Œåƒ…ä¿ç•™è·¯æ®µ+é–€ç‰Œ
    """
    s = str(addr).strip()
    if not s:
        return ""
    s = fullwidth_to_halfwidth(s)

    # å»é™¤ç¸£å¸‚
    for city in CITIES:
        if s.startswith(city):
            s = s[len(city):]
            break

    # å»é™¤é„‰é®å¸‚å€
    for _ in range(2):
        s = re.sub(r"^[\u4e00-\u9fff]{1,3}[å€é®é„‰å¸‚]", "", s)

    # å»é™¤é‡Œé„°
    s = re.sub(r"[\u4e00-\u9fff]*é‡Œ\d*é„°?", "", s)
    s = re.sub(r"\d+é„°", "", s)

    # å»é™¤æ¨“å±¤
    s = re.sub(r"[,\s]*(åœ°ä¸‹)?[\d]+æ¨“.*$", "", s)
    s = re.sub(
        r"[,\s]*(åœ°ä¸‹)?(å|äºŒå|ä¸‰å)?[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+æ¨“.*$", "", s
    )
    s = re.sub(r"\s*\d+F$", "", s)

    # å»é™¤æ£Ÿè™Ÿ
    s = re.sub(r"\s*[A-Za-z]\d*[-]\d+F$", "", s)
    s = re.sub(r"\s*[A-Za-z]\d*æ£Ÿ.*$", "", s)
    s = re.sub(r"\s+[A-Za-z]\d+[-][A-Za-z]?\d*F?$", "", s)

    # å»é™¤ã€Œæ—ã€ã€Œä¹‹Xã€ã€Œå…±Nç­†ã€
    s = re.sub(r"æ—.*$", "", s)
    s = re.sub(r"ä¹‹\d+$", "", s)
    s = re.sub(r"å…±\d+ç­†$", "", s)
    s = re.sub(r"\s+", "", s)

    return s.strip()


def extract_road_number(addr: str) -> str:
    m = re.search(r"(.*?\d+è™Ÿ)", addr)
    return m.group(1) if m else addr


def extract_road_alley(addr: str) -> str:
    m = re.search(r"(.*?\d+å··)", addr)
    return m.group(1) if m else ""


def extract_road(addr: str) -> str:
    m = re.search(
        r"([\u4e00-\u9fff]+(?:è·¯|è¡—|å¤§é“)(?:[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+æ®µ)?)", addr
    )
    return m.group(1) if m else ""


# ========== ä¸»ç¨‹å¼ ==========

def build_from_b_table():
    """å¾ B è¡¨åŒ¯å…¥è³‡æ–™"""
    if not B_TABLE.exists():
        print(f"âŒ B è¡¨ä¸å­˜åœ¨: {B_TABLE}")
        return {}

    print(f"ğŸ“– è®€å– B è¡¨: {B_TABLE.name}")
    
    mapping = defaultdict(lambda: {
        "communities": defaultdict(int),
        "normalized": "",
        "to_number": "",
        "to_alley": "",
        "road": "",
        "city": "",
        "district": "",
        "source": "Bè¡¨",
    })

    count = 0
    with open(B_TABLE, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            count += 1
            if count % 100000 == 0:
                print(f"  â³ å·²è™•ç† {count:,} ç­†...")

            address = row.get("åœŸåœ°ä½ç½®å»ºç‰©é–€ç‰Œ", "").strip()
            community = row.get("å»ºæ¡ˆåç¨±", "").strip()
            total_price = row.get("ç¸½åƒ¹å…ƒ", "").strip()

            # éæ¿¾: éœ€è¦æœ‰ç¤¾å€åå’Œæ­£å¸¸æˆäº¤åƒ¹
            if not address or not community:
                continue
            try:
                price = float(total_price) if total_price else 0
                if price <= 0:
                    continue
            except ValueError:
                continue

            # æ­£è¦åŒ–åœ°å€
            norm = normalize_address(address)
            if not norm:
                continue

            city, district = extract_city_district(address)
            to_number = extract_road_number(norm)
            to_alley = extract_road_alley(norm)
            road = extract_road(norm)

            key = norm
            mapping[key]["communities"][community] += 1
            mapping[key]["normalized"] = norm
            mapping[key]["to_number"] = to_number
            mapping[key]["to_alley"] = to_alley
            mapping[key]["road"] = road
            mapping[key]["city"] = city
            mapping[key]["district"] = district

    print(f"  âœ… è®€å–å®Œæˆ: {count:,} ç­†äº¤æ˜“")
    print(f"  ğŸ“Š ç”¢ç”Ÿ {len(mapping):,} å€‹å”¯ä¸€åœ°å€")
    
    return mapping


def load_manual_mapping():
    """è®€å–æ‰‹å‹•å°ç…§"""
    manual = {}
    if not MANUAL_CSV.exists():
        create_manual_template()
        return manual

    print(f"ğŸ“– è®€å–æ‰‹å‹•å°ç…§: {MANUAL_CSV.name}")
    with open(MANUAL_CSV, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            addr = row.get("åœ°å€", "").strip()
            community = row.get("ç¤¾å€åç¨±", "").strip()
            district = row.get("é„‰é®å¸‚å€", "").strip()

            if addr and community:
                norm = normalize_address(addr)
                if norm:
                    manual[norm] = {
                        "community": community,
                        "city": extract_city_district(addr)[0],
                        "district": district,
                        "source": "æ‰‹å‹•",
                    }
    
    print(f"  âœ… è®€å–å®Œæˆ: {len(manual)} ç­†æ‰‹å‹•å°ç…§")
    return manual


def create_manual_template():
    """å»ºç«‹æ‰‹å‹•å°ç…§è¡¨ç¯„æœ¬"""
    if MANUAL_CSV.exists():
        return
    print(f"ğŸ“ å»ºç«‹æ‰‹å‹•å°ç…§è¡¨ç¯„æœ¬ ({MANUAL_CSV.name})...")
    with open(MANUAL_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["åœ°å€", "ç¤¾å€åç¨±", "é„‰é®å¸‚å€", "å‚™è¨»"])
        writer.writerow(["ä¸‰æ°‘è·¯29å··5è™Ÿ", "å¥å®‰æ–°åŸFå€", "æ¾å±±å€", ""])
        writer.writerow(["ä¸‰æ°‘è·¯29å··3è™Ÿ", "å¥å®‰æ–°åŸFå€", "æ¾å±±å€", ""])
        writer.writerow(["ä¸‰æ°‘è·¯29å··1è™Ÿ", "å¥å®‰æ–°åŸFå€", "æ¾å±±å€", ""])
        writer.writerow(["ä¸‰æ°‘è·¯29å··7è™Ÿ", "å¥å®‰æ–°åŸFå€", "æ¾å±±å€", ""])
        writer.writerow(["ä»æ„›è·¯ä¸‰æ®µ53è™Ÿ", "ä»æ„›å¸å¯¶", "å¤§å®‰å€", ""])
        writer.writerow(["å»¶å£½è¡—330è™Ÿ", "å¹³å®‰æ–°åŸç”²å€", "æ¾å±±å€", ""])
        writer.writerow(["å»¶å£½è¡—332è™Ÿ", "å¹³å®‰æ–°åŸç”²å€", "æ¾å±±å€", ""])
        writer.writerow(["å»¶å£½è¡—334è™Ÿ", "å¹³å®‰æ–°åŸç”²å€", "æ¾å±±å€", ""])
        writer.writerow(["æ—¥èˆˆä¸€è¡—6è™Ÿ", "ä»ç™¼å–œæ‚…", "ç«¹åŒ—å¸‚", ""])


def merge_and_export(b_mapping: dict, manual: dict):
    """åˆä½µä¸¦è¼¸å‡ºåˆ° CSV"""
    print(f"\nğŸ’¾ å¯«å…¥ CSV: {OUTPUT_CSV.name}")

    # æº–å‚™ CSV åˆ—
    rows = []

    # 1. å¾ B è¡¨åŒ¯å…¥ï¼ˆå„ªå…ˆé †åºï¼šäº¤æ˜“ç­†æ•¸å¤šçš„ç¤¾å€æ’å‰ï¼‰
    for norm, data in sorted(b_mapping.items()):
        # ç¤¾å€åç¨±æ’åºï¼ˆäº¤æ˜“å¤šçš„å„ªå…ˆï¼‰
        communities = sorted(
            data["communities"].items(),
            key=lambda x: -x[1]
        )
        
        for community, count in communities:
            # å¦‚æœæ‰‹å‹•æœ‰å°ç…§ï¼Œå„ªå…ˆç”¨æ‰‹å‹•çš„ï¼ˆè¦†è“‹ï¼‰
            if norm in manual:
                m = manual[norm]
                rows.append({
                    "æ­£è¦åŒ–åœ°å€": norm,
                    "åˆ°è™Ÿåœ°å€": data["to_number"],
                    "åˆ°å··åœ°å€": data["to_alley"],
                    "è·¯æ®µ": data["road"],
                    "ç¤¾å€åç¨±": m["community"],
                    "ç¸£å¸‚": m["city"],
                    "é„‰é®å¸‚å€": m["district"],
                    "äº¤æ˜“ç­†æ•¸": 0,
                    "è³‡æ–™ä¾†æº": "æ‰‹å‹•",
                    "æ‰€æœ‰å»ºæ¡ˆå": "",
                })
                break  # æ‰‹å‹•å·²è¦†è“‹ï¼Œè·³éå…¶ä»–å»ºæ¡ˆ
            else:
                all_names = ",".join([c[0] for c in communities])
                rows.append({
                    "æ­£è¦åŒ–åœ°å€": norm,
                    "åˆ°è™Ÿåœ°å€": data["to_number"],
                    "åˆ°å··åœ°å€": data["to_alley"],
                    "è·¯æ®µ": data["road"],
                    "ç¤¾å€åç¨±": community,
                    "ç¸£å¸‚": data["city"],
                    "é„‰é®å¸‚å€": data["district"],
                    "äº¤æ˜“ç­†æ•¸": count,
                    "è³‡æ–™ä¾†æº": "Bè¡¨",
                    "æ‰€æœ‰å»ºæ¡ˆå": all_names,
                })

    # 2. æ‰‹å‹•å°ç…§ï¼ˆè‹¥æœªè¢« B è¡¨æ¶µè“‹ï¼‰
    for norm, m in manual.items():
        if not any(r["æ­£è¦åŒ–åœ°å€"] == norm for r in rows):
            rows.append({
                "æ­£è¦åŒ–åœ°å€": norm,
                "åˆ°è™Ÿåœ°å€": extract_road_number(norm),
                "åˆ°å··åœ°å€": extract_road_alley(norm),
                "è·¯æ®µ": extract_road(norm),
                "ç¤¾å€åç¨±": m["community"],
                "ç¸£å¸‚": m["city"],
                "é„‰é®å¸‚å€": m["district"],
                "äº¤æ˜“ç­†æ•¸": 0,
                "è³‡æ–™ä¾†æº": "æ‰‹å‹•",
                "æ‰€æœ‰å»ºæ¡ˆå": "",
            })

    # å¯«å…¥ CSV
    fieldnames = [
        "æ­£è¦åŒ–åœ°å€", "åˆ°è™Ÿåœ°å€", "åˆ°å··åœ°å€", "è·¯æ®µ",
        "ç¤¾å€åç¨±", "ç¸£å¸‚", "é„‰é®å¸‚å€", "äº¤æ˜“ç­†æ•¸",
        "è³‡æ–™ä¾†æº", "æ‰€æœ‰å»ºæ¡ˆå"
    ]
    
    with open(OUTPUT_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)

    print(f"  âœ… å¯«å…¥å®Œæˆ: {len(rows):,} ç­†è¨˜éŒ„")
    return len(rows)


def main():
    print("=" * 60)
    print("ğŸ”¨ å»ºç«‹åœ°å€â†’ç¤¾å€åç¨± å°ç…§è¡¨ (CSV ç‰ˆ)")
    print("=" * 60)

    # 1. è®€å– B è¡¨
    b_mapping = build_from_b_table()
    
    # 2. è®€å–æ‰‹å‹•å°ç…§
    manual = load_manual_mapping()
    
    # 3. åˆä½µä¸¦è¼¸å‡º
    total = merge_and_export(b_mapping, manual)

    # 4. çµ±è¨ˆ
    file_size_mb = OUTPUT_CSV.stat().st_size / (1024 * 1024)
    print(f"\nğŸ“Š çµ±è¨ˆ:")
    print(f"  â€¢ å¾ B è¡¨: {len(b_mapping):,} ç­†")
    print(f"  â€¢ æ‰‹å‹•å°ç…§: {len(manual):,} ç­†")
    print(f"  â€¢ è¼¸å‡ºç¸½è¨ˆ: {total:,} ç­†")
    print(f"  â€¢ CSV æª”æ¡ˆ: {file_size_mb:.1f} MB")
    print("=" * 60)
    print("âœ… å®Œæˆï¼å¯ç”¨ address2community.py é€²è¡ŒæŸ¥è©¢")
    print("=" * 60)


if __name__ == "__main__":
    main()
